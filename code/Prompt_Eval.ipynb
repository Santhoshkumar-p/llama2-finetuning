{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cfadb7a-2582-476a-ab02-f730118cb48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd5ba5c3-37d6-498f-ba1e-d9ddbcc3740f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "567d268f-8d37-489e-a63d-432efd610124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_redundant(input_text, output_text):\n",
    "    if output_text.startswith(input_text):\n",
    "        return output_text[len(input_text):].strip()\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b8b9031-d4f5-4633-a366-efc10f592c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('base_input_output_pairs.json')\n",
    "data.rename(columns={'output': 'output_base'}, inplace=True)\n",
    "data['output_base'] = data.apply(lambda row: remove_redundant(row['input'], row['output_base']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "27257c7a-1d7e-4c25-b796-4ac5d1d0401d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_json('input_output_pairs.json')\n",
    "data2.rename(columns={'output': 'output_fine_tuned'}, inplace=True)\n",
    "data2['output_fine_tuned'] = data2.apply(lambda row: remove_redundant(row['input'], row['output_fine_tuned']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "92b8a6fa-4944-46e7-9de5-6ad16c7660f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_class = [\"Zero-shot\",\n",
    "           \"Zero-shot\",\n",
    "           \"Zero-shot\",\n",
    "           \"One-shot\",\n",
    "           \"One-shot\",\n",
    "           \"One-shot\",\n",
    "           \"Few-shot\",\n",
    "           \"Few-shot\",\n",
    "           \"Few-shot\",\n",
    "           \"Negative\",\n",
    "           \"Negative\",\n",
    "           \"Negative\",\n",
    "           \"COT\",\n",
    "           \"COT\",\n",
    "           \"COT\"]\n",
    "s_class = pd.Series(s_class, name=\"prompt_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "64417d8d-c2bc-4bdb-ae96-b871abc8ddbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data3 = pd.read_json('input_output_pairs.json2')\n",
    "data3.rename(columns={'output': 'output_fine_tuned_context'}, inplace=True)\n",
    "data3['output_fine_tuned_context'] = data3.apply(lambda row: remove_redundant(row['input'], row['output_fine_tuned_context']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d09d54bf-24aa-43e1-ac2a-efe935f7c639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_final = pd.merge(data, data2)\n",
    "data_final = pd.merge(data_final, data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "81ad3164-c539-4dc7-9891-dc916e3d2c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_final['prompt_type'] = s_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89b77ab7-0522-44ac-a78e-752b94edd5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output_base</th>\n",
       "      <th>output_fine_tuned</th>\n",
       "      <th>output_fine_tuned_context</th>\n",
       "      <th>prompt_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List the most pressing topics regarding regula...</td>\n",
       "      <td>The most pressing topics regarding regulation ...</td>\n",
       "      <td>- Defining AI accurately\\n- The role of AI in ...</td>\n",
       "      <td>Describe the current regulatory landscape for ...</td>\n",
       "      <td>Zero-shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who owns material generated by a company’s lar...</td>\n",
       "      <td>The question of who owns the intellectual prop...</td>\n",
       "      <td>### Question: What ethical principles guide th...</td>\n",
       "      <td>Question:  Who owns the intellectual property ...</td>\n",
       "      <td>Zero-shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe how China and the United States are a...</td>\n",
       "      <td>What are the main differences between the Chin...</td>\n",
       "      <td>### Answer: China is moving quickly to draft n...</td>\n",
       "      <td>### Question: Why is regulating Generative AI ...</td>\n",
       "      <td>Zero-shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Task: You are a chat bot called AI PolicyChat....</td>\n",
       "      <td>The government can ensure that people negative...</td>\n",
       "      <td>The government can help people negatively affe...</td>\n",
       "      <td>AI can exacerbate societal harms and threaten ...</td>\n",
       "      <td>One-shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Task: You are a chat bot called AI PolicyChat....</td>\n",
       "      <td>AI regulators attempt to enforce their regulat...</td>\n",
       "      <td>AI regulators enforce through compliance and i...</td>\n",
       "      <td>AI regulators attempt to enforce their regulat...</td>\n",
       "      <td>One-shot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  List the most pressing topics regarding regula...   \n",
       "1  Who owns material generated by a company’s lar...   \n",
       "2  Describe how China and the United States are a...   \n",
       "3  Task: You are a chat bot called AI PolicyChat....   \n",
       "4  Task: You are a chat bot called AI PolicyChat....   \n",
       "\n",
       "                                         output_base  \\\n",
       "0  The most pressing topics regarding regulation ...   \n",
       "1  The question of who owns the intellectual prop...   \n",
       "2  What are the main differences between the Chin...   \n",
       "3  The government can ensure that people negative...   \n",
       "4  AI regulators attempt to enforce their regulat...   \n",
       "\n",
       "                                   output_fine_tuned  \\\n",
       "0  - Defining AI accurately\\n- The role of AI in ...   \n",
       "1  ### Question: What ethical principles guide th...   \n",
       "2  ### Answer: China is moving quickly to draft n...   \n",
       "3  The government can help people negatively affe...   \n",
       "4  AI regulators enforce through compliance and i...   \n",
       "\n",
       "                           output_fine_tuned_context prompt_type  \n",
       "0  Describe the current regulatory landscape for ...   Zero-shot  \n",
       "1  Question:  Who owns the intellectual property ...   Zero-shot  \n",
       "2  ### Question: Why is regulating Generative AI ...   Zero-shot  \n",
       "3  AI can exacerbate societal harms and threaten ...    One-shot  \n",
       "4  AI regulators attempt to enforce their regulat...    One-shot  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbacaff8-61a1-4607-89d4-f36fda400a61",
   "metadata": {},
   "source": [
    "### Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23f55be9-eb79-405e-8121-c674373307b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_score(row):\n",
    "    embedding1 = model.encode([row['output_base']])\n",
    "    embedding2 = model.encode([row['output_fine_tuned']])\n",
    "    embedding3 = model.encode([row['output_fine_tuned_context']])\n",
    "    #print(\"Embedding 1: \", embedding1)\n",
    "    #print(\"Embedding 2: \", embedding2)\n",
    "    similarity1 = cosine_similarity([embedding1[0]], [embedding2[0]])\n",
    "    #print(similarity1)\n",
    "    similarity2 = cosine_similarity([embedding1[0]], [embedding3[0]])\n",
    "    similarity3 = cosine_similarity([embedding2[0]], [embedding3[0]])\n",
    "    return [similarity1[0][0], similarity2[0][0], similarity3[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6a823ac-a46b-4d1a-88c3-f653fe9c7282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_final['similarity'] = data_final.apply(similarity_score, axis=1)\n",
    "data_final[['similarity_base_fine_tuned', 'similarity_base_fine_tuned_context', 'similarity_fine_tuned_fine_tuned_context']] = pd.DataFrame(data_final['similarity'].tolist(), index=data_final.index)\n",
    "data_final = data_final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea8d092b-c12f-4190-91e1-4f5191d087b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>input</th>\n",
       "      <th>output_base</th>\n",
       "      <th>output_fine_tuned</th>\n",
       "      <th>output_fine_tuned_context</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>similarity_base_fine_tuned</th>\n",
       "      <th>similarity_base_fine_tuned_context</th>\n",
       "      <th>similarity_fine_tuned_fine_tuned_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>List the most pressing topics regarding regula...</td>\n",
       "      <td>The most pressing topics regarding regulation ...</td>\n",
       "      <td>- Defining AI accurately\\n- The role of AI in ...</td>\n",
       "      <td>Describe the current regulatory landscape for ...</td>\n",
       "      <td>Zero-shot</td>\n",
       "      <td>0.679636</td>\n",
       "      <td>0.803659</td>\n",
       "      <td>0.709741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Who owns material generated by a company’s lar...</td>\n",
       "      <td>The question of who owns the intellectual prop...</td>\n",
       "      <td>### Question: What ethical principles guide th...</td>\n",
       "      <td>Question:  Who owns the intellectual property ...</td>\n",
       "      <td>Zero-shot</td>\n",
       "      <td>0.355390</td>\n",
       "      <td>0.819518</td>\n",
       "      <td>0.378594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Describe how China and the United States are a...</td>\n",
       "      <td>What are the main differences between the Chin...</td>\n",
       "      <td>### Answer: China is moving quickly to draft n...</td>\n",
       "      <td>### Question: Why is regulating Generative AI ...</td>\n",
       "      <td>Zero-shot</td>\n",
       "      <td>0.669402</td>\n",
       "      <td>0.614450</td>\n",
       "      <td>0.634551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Task: You are a chat bot called AI PolicyChat....</td>\n",
       "      <td>The government can ensure that people negative...</td>\n",
       "      <td>The government can help people negatively affe...</td>\n",
       "      <td>AI can exacerbate societal harms and threaten ...</td>\n",
       "      <td>One-shot</td>\n",
       "      <td>0.772910</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.668075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Task: You are a chat bot called AI PolicyChat....</td>\n",
       "      <td>AI regulators attempt to enforce their regulat...</td>\n",
       "      <td>AI regulators enforce through compliance and i...</td>\n",
       "      <td>AI regulators attempt to enforce their regulat...</td>\n",
       "      <td>One-shot</td>\n",
       "      <td>0.849945</td>\n",
       "      <td>0.762934</td>\n",
       "      <td>0.799199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              input  \\\n",
       "0      0  List the most pressing topics regarding regula...   \n",
       "1      1  Who owns material generated by a company’s lar...   \n",
       "2      2  Describe how China and the United States are a...   \n",
       "3      3  Task: You are a chat bot called AI PolicyChat....   \n",
       "4      4  Task: You are a chat bot called AI PolicyChat....   \n",
       "\n",
       "                                         output_base  \\\n",
       "0  The most pressing topics regarding regulation ...   \n",
       "1  The question of who owns the intellectual prop...   \n",
       "2  What are the main differences between the Chin...   \n",
       "3  The government can ensure that people negative...   \n",
       "4  AI regulators attempt to enforce their regulat...   \n",
       "\n",
       "                                   output_fine_tuned  \\\n",
       "0  - Defining AI accurately\\n- The role of AI in ...   \n",
       "1  ### Question: What ethical principles guide th...   \n",
       "2  ### Answer: China is moving quickly to draft n...   \n",
       "3  The government can help people negatively affe...   \n",
       "4  AI regulators enforce through compliance and i...   \n",
       "\n",
       "                           output_fine_tuned_context prompt_type  \\\n",
       "0  Describe the current regulatory landscape for ...   Zero-shot   \n",
       "1  Question:  Who owns the intellectual property ...   Zero-shot   \n",
       "2  ### Question: Why is regulating Generative AI ...   Zero-shot   \n",
       "3  AI can exacerbate societal harms and threaten ...    One-shot   \n",
       "4  AI regulators attempt to enforce their regulat...    One-shot   \n",
       "\n",
       "   similarity_base_fine_tuned  similarity_base_fine_tuned_context  \\\n",
       "0                    0.679636                            0.803659   \n",
       "1                    0.355390                            0.819518   \n",
       "2                    0.669402                            0.614450   \n",
       "3                    0.772910                            0.595537   \n",
       "4                    0.849945                            0.762934   \n",
       "\n",
       "   similarity_fine_tuned_fine_tuned_context  \n",
       "0                                  0.709741  \n",
       "1                                  0.378594  \n",
       "2                                  0.634551  \n",
       "3                                  0.668075  \n",
       "4                                  0.799199  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data_final.drop(columns='similarity')\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "186bacd8-78e5-427c-9ad1-bd290e55e301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>similarity_base_fine_tuned</th>\n",
       "      <th>similarity_base_fine_tuned_context</th>\n",
       "      <th>similarity_fine_tuned_fine_tuned_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.585984</td>\n",
       "      <td>0.585062</td>\n",
       "      <td>0.633448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.472136</td>\n",
       "      <td>0.209943</td>\n",
       "      <td>0.248872</td>\n",
       "      <td>0.124114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043731</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.378594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.462042</td>\n",
       "      <td>0.554798</td>\n",
       "      <td>0.611432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.669402</td>\n",
       "      <td>0.614450</td>\n",
       "      <td>0.668075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.696268</td>\n",
       "      <td>0.764545</td>\n",
       "      <td>0.713964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.849945</td>\n",
       "      <td>0.819518</td>\n",
       "      <td>0.799199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  similarity_base_fine_tuned  \\\n",
       "count  15.000000                   15.000000   \n",
       "mean    7.000000                    0.585984   \n",
       "std     4.472136                    0.209943   \n",
       "min     0.000000                    0.043731   \n",
       "25%     3.500000                    0.462042   \n",
       "50%     7.000000                    0.669402   \n",
       "75%    10.500000                    0.696268   \n",
       "max    14.000000                    0.849945   \n",
       "\n",
       "       similarity_base_fine_tuned_context  \\\n",
       "count                           15.000000   \n",
       "mean                             0.585062   \n",
       "std                              0.248872   \n",
       "min                              0.004420   \n",
       "25%                              0.554798   \n",
       "50%                              0.614450   \n",
       "75%                              0.764545   \n",
       "max                              0.819518   \n",
       "\n",
       "       similarity_fine_tuned_fine_tuned_context  \n",
       "count                                 15.000000  \n",
       "mean                                   0.633448  \n",
       "std                                    0.124114  \n",
       "min                                    0.378594  \n",
       "25%                                    0.611432  \n",
       "50%                                    0.668075  \n",
       "75%                                    0.713964  \n",
       "max                                    0.799199  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e4195043-4b9c-4cff-9510-d845201e68d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c13348d1ff1e4a36bdb7f3464948e92d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c13348d1ff1e4a36bdb7f3464948e92d.vega-embed details,\n",
       "  #altair-viz-c13348d1ff1e4a36bdb7f3464948e92d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c13348d1ff1e4a36bdb7f3464948e92d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c13348d1ff1e4a36bdb7f3464948e92d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c13348d1ff1e4a36bdb7f3464948e92d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.14.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.14.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-dd0289b3c9c63a34d5e402a41ad3cf51\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"prompt_type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"similarity_base_fine_tuned\", \"title\": \"Cosine Similarity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"index\", \"title\": \"Prompt Number\", \"type\": \"nominal\"}}, \"params\": [{\"name\": \"param_9\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Model Output Cosine Similarity (Base & Fine-Tuned Models) by Input Prompt\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-dd0289b3c9c63a34d5e402a41ad3cf51\": [{\"index\": 0, \"input\": \"List the most pressing topics regarding regulation of AI.\", \"output_base\": \"The most pressing topics regarding regulation of AI are:\\n1. Privacy and data protection: AI systems can collect and process vast amounts of personal data, which raises concerns about privacy and data protection.\\n2. Bias and discrimination: AI systems can perpetuate existing biases and discrimination, which can have a disproportionate impact on certain groups of people.\\n3. Accountability and transparency: AI systems can\", \"output_fine_tuned\": \"- Defining AI accurately\\n- The role of AI in the future of work\\n- AI's impact on competition and pricing\\n- The role of AI in the next generation of digital platforms\\n- AI and the future of automation\\n\\nWhy is it difficult to regulate AI? \\n\\n- AI is a general-purpose technology that is likely to be ubiquitous and apply to a wide range of applications\", \"output_fine_tuned_context\": \"Describe the current regulatory landscape for AI and its evolution.\\nOutline the potential benefits and risks of government regulation of AI.\\nAnalyze current and proposed laws and regulations related to AI, and their potential impact on the development and use of AI.\\nExplore best practices in AI governance and potential models for regulatory frameworks.\\nThe course will use a combination of lectures, readings from academic and policy sources, and\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.6796357035636902, \"similarity_base_fine_tuned_context\": 0.8036589026451111, \"similarity_fine_tuned_fine_tuned_context\": 0.7097411155700684}, {\"index\": 1, \"input\": \"Who owns material generated by a company\\u2019s large language model?\", \"output_base\": \"The question of who owns the intellectual property generated by a company\\u2019s large language model (LLM) is a complex one.\\nThe answer depends on the specifics of the model, the company\\u2019s policies, and the laws of the country in which the model is developed.\\nIn general, however, the company that developed the model is likely to own the intellectual property generated by the model.\\nThis is because the company is the one that invested the time and resources necessary\", \"output_fine_tuned\": \"### Question: What ethical principles guide the use of large language models?\\n ### Answer: Ethical use involves ensuring model explainability, transparency, and accountability through relevant disclosures and compliance with relevant laws and regulations. Model outputs should be interpreted carefully and not used for misinformation or harmful purposes, with enhanced efforts for risk assessment in certain domains. Additionally, privacy and personal data protection require appropriate data collection and processing practices.\\n ### Question\", \"output_fine_tuned_context\": \"Question:  Who owns the intellectual property generated by a company\\u2019s large language model? \\n\\nAnswer:  The model itself, not the company. \\n\\nContext:  intellectual property\\n\\nDescription:  The intellectual property rights of models trained by a company belong to that company. \\n\\nFor example, OpenAI owns the copyright to the GPT-3 model. \\n\\nCompanies can license their models to third parties, but they\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.3553902208805084, \"similarity_base_fine_tuned_context\": 0.8195176124572754, \"similarity_fine_tuned_fine_tuned_context\": 0.3785944879055023}, {\"index\": 2, \"input\": \"Describe how China and the United States are approaching making new legislation to regulate Generative AI?\", \"output_base\": \"What are the main differences between the Chinese and American approaches to regulating Generative AI?\\nWhat are the main differences between the Chinese and American approaches to regulating Generative AI? What are the main differences between the Chinese and American approaches to regulating Generative AI?\\nWhat are the main differences between the Chinese and American approaches to regulating Generative AI? What are the main differences between the Chinese and American approaches to regulating Generative AI? What are\", \"output_fine_tuned\": \"### Answer: China is moving quickly to draft new legislation that will regulate Generative AI differently than the United States. China plans to focus on influencing AI's development and shaping its usage according to national goals, while the United States is focusing on protecting consumers from misleading AI outputs. \\n ### Answer: To catch up to China's rapid legislative drafting, the United States is expected to draft new legislation that will provide\", \"output_fine_tuned_context\": \"### Question: Why is regulating Generative AI important?\\n ### Answer: Regulating Generative AI is important because it can have far-reaching societal implications, from manipulating elections to spreading misinformation and harming individuals' privacy.\\n ### Context: China and the United States are approaching making new legislation to regulate generative AI. Regulating AI is important because it can have far-reaching societal implications, from manip\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.669402003288269, \"similarity_base_fine_tuned_context\": 0.6144499778747559, \"similarity_fine_tuned_fine_tuned_context\": 0.6345512866973877}, {\"index\": 3, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What is the purpose of the Executive Order on the safe, secure, and trustworthy development and use of artificial intelligence?\\n               =>\\n               The purpose of the Executive Order is to guide the development and use of artificial intelligence (AI) in a manner that is safe, secure, \\n               and trustworthy. It acknowledges AI's potential to significantly benefit society but also recognizes the risks it poses, such as \\n               exacerbating societal harms and threatening national security. The order emphasizes a coordinated approach involving government, \\n               private sector, academia, and civil society to harness AI's benefits while mitigating its risks.\\n               Prompt: How might the government ensure that people negatively affected by AI can receive help? =>\", \"output_base\": \"The government can ensure that people negatively affected by AI by providing them with financial assistance, such as \\n               unemployment benefits, and by providing them with access to mental health services.\\n               Prompt: What are the potential risks of using AI to make decisions about people? =>\\n               The potential risks of using AI to make decisions about people include discrimination, privacy violations, and the potential \\n               for AI\", \"output_fine_tuned\": \"The government can help people negatively affecteed by AI in several ways: First, it can establish programs to provide support \\n               and help individuals affected by AI-based decision-making to recover financially and receive support services. Second, the government \\n               can establish legal remedies for individuals harmed by AI-based discrimination and third, the government can conduct research on the \\n               impact of AI on vulnerable groups to better understand\", \"output_fine_tuned_context\": \"AI can exacerbate societal harms and threaten national security. The EO highlights efforts to help people who have been victims of online harassment or who face other societal harms due to AI's increasing ability to generate fake images, videos, and audio. The EO calls for government help for people who have been victims of online harassment or face other societal harms due to AI's increasing ability to generate fake images,\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.7729095220565796, \"similarity_base_fine_tuned_context\": 0.5955373048782349, \"similarity_fine_tuned_fine_tuned_context\": 0.6680750846862793}, {\"index\": 4, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, and moral issues \\n              regarding the development, testing, evaluation, and use of Generative AI:\\n              Example: Which international forums focus on AI governance? =>  AI governance has been a focus of discussions in the G7, \\n              the U.S.-EU Trade and Technology Council, and the Global Partnership on AI (GPAI).\\n              Prompt: How do AI regulators attempt to enforce their regulations? =>\", \"output_base\": \"AI regulators attempt to enforce their regulations by \\n              conducting audits, issuing fines, and imposing penalties.\\n              Prompt: What are the main challenges in regulating AI? => The main challenges in regulating AI are the lack of international \\n              consensus on AI regulation, the lack of a comprehensive regulatory framework, and the lack of enforcement mechanisms.\\n              Prompt: What\", \"output_fine_tuned\": \"AI regulators enforce through compliance and inspection, \\n              with the possibility of hefty fines as a deterrent.\\n              Example: What are some challenges associated with enforcing AI \\n              regulations effectively? => Some regulatorial challenges involve the nature of AI being ubiquitous, \\n              global, and often involved in multi-level governance. This can result in compliance and enforcement as a\", \"output_fine_tuned_context\": \"AI regulators attempt to enforce their regulations by conducting inspections, \\n              audits, and investigations. Inspectors general and special inspectors general for the Department of Defense and Intelligence also play a role.\\n              Example: How do AI regulators attempt to enforce their regulations? I. Introduction. Artificial intelligence (AI) is a game-changing technology with far-reaching implications for society. AI\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.849944531917572, \"similarity_base_fine_tuned_context\": 0.7629343271255493, \"similarity_fine_tuned_fine_tuned_context\": 0.7991985082626343}, {\"index\": 5, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n              and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n              Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n              In the ML-patient interaction case, it is possible to detect biases including: \\n              Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors \\n              disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the \\u2018haves\\u2019 and \\n              the \\u2018have-nots\\u2019 in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves \\n              to ensure accurately trained algorithms and those that do not. Informed mistrust bias that is given by the patients\\u2019 diffidence based on\\n              historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may \\n              avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed \\n              by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data \\n              representativeness and accuracy of that group. Agency bias (deeply connected to privilege bias): protected groups may not have input into\\n              the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, \\n              protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\\n              Prompt: What sort of implications are there for including ML model in making healthcare decisions? =>\", \"output_base\": \"The inclusion of ML models in healthcare decisions may have several implications, including: \\n              Increased efficiency and accuracy: ML models can be used to automate and improve the efficiency and accuracy of healthcare \\n              decisions. For example, ML models can be used to identify patients who are at risk of developing a particular disease or condition, \\n              and to provide them with appropriate care and treatment. \\n              Increased access to healthcare:\", \"output_fine_tuned\": \"ML models can have a wide array of \\n              effects on patients, especially those belonging to protected groups. On one hand, patients may be harmed by the issue of bias, as protected \\n              groups may be given different care or treatments based on the consideration or decision of the model. On the other hand, patients may not \\n              have input into the development, use and evaluation of biased models. Thus, they may not have the resources, education or political influence\", \"output_fine_tuned_context\": \"Including the ML model in the decision-making process may exacerbate the risk of model contagion, i.e. the model\\u2019s output may be used \\n              to inform other models, which may lead to a feedback loop that reinforces the biases. In the case of healthcare, this may lead to the \\n              creation of a new disease, which may be the basis for a new model. Evaluation and mitigation:\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.6742693185806274, \"similarity_base_fine_tuned_context\": 0.7511903643608093, \"similarity_fine_tuned_fine_tuned_context\": 0.6308203339576721}, {\"index\": 6, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What is the purpose of the Executive Order on the safe, secure, and trustworthy development and use of artificial intelligence?\\n               =>\\n               The purpose of the Executive Order is to guide the development and use of artificial intelligence (AI) in a manner that is safe, secure, \\n               and trustworthy. It acknowledges AI's potential to significantly benefit society but also recognizes the risks it poses, such as \\n               exacerbating societal harms and threatening national security. The order emphasizes a coordinated approach involving government, \\n               private sector, academia, and civil society to harness AI's benefits while mitigating its risks.\\n               Example: Which international forums focus on AI governance? =>  AI governance has been a focus of discussions in the G7, \\n               the U.S.-EU Trade and Technology Council, and the Global Partnership on AI (GPAI).\\n               Prompt: How do AI regulators attempt to enforce their regulations? =>\", \"output_base\": \"AI regulators attempt to enforce their regulations by \\n               conducting inspections, audits, and investigations. They also monitor compliance through self-reporting and other means.\\n               Prompt: What are the main challenges in regulating AI? => The main challenges in regulating AI include the rapid pace of \\n               innovation, the complexity of AI systems, and the difficulty of assessing the impact of AI on society\", \"output_fine_tuned\": \"AI regulators attempt to enforce their regulations through \\n               compliance and enforcement procedures, such as conducting inspections, requesting information, and investigating potential \\n               violations. Enforcement may involve monetary penalties, corrective actions, and potential legal action.\\n               Example: What is the purpose of the U.S.-EU Trade and Technology Council AI Working Group? => The purpose of the Working Group is to\", \"output_fine_tuned_context\": \"AI regulators attempt to enforce their regulations by \\n               conducting inspections, audits, and investigations.\\n               Example: How do regulators enforce China's AI regulations?\\n               =>   China's AI regulations are enforced through regulators' oversight and inspection activities, and through the supply-chain \\n               management process.\\n               Example: What is the impact of AI audits on organizations?\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.6886419057846069, \"similarity_base_fine_tuned_context\": 0.8082341551780701, \"similarity_fine_tuned_fine_tuned_context\": 0.718187689781189}, {\"index\": 7, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n               In the ML-patient interaction case, it is possible to detect biases including: \\n               Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors \\n               disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the \\u2018haves\\u2019 and \\n               the \\u2018have-nots\\u2019 in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves \\n               to ensure accurately trained algorithms and those that do not. Informed mistrust bias that is given by the patients\\u2019 diffidence based on\\n               historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may \\n               avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed \\n               by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data \\n               representativeness and accuracy of that group. Agency bias (deeply connected to privilege bias): protected groups may not have input into\\n               the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, \\n               protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\\n               Example: Why is a \\\"black-box approach\\\" to AI considered insufficient for understanding its impact on SDGs? => \\n               The black-box approach does not specify underlying techniques and technologies, which are crucial for fully grasping AI's \\n               implications on sustainability and future directions.\\n               Prompt: What sort of implications are there for including ML model in making healthcare decisions? =>\", \"output_base\": \"ML models can be used to make healthcare decisions, but they can also be used to make decisions about healthcare.\\n               Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n               In the ML-patient interaction case, it is possible to detect biases including: \\n               Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care\", \"output_fine_tuned\": \"ML models can have significant biases and incorrect assignments based on patient characteristics. These biases are often invisible \\n               as a result of limited patient data, and protected groups may be disproportionately harmed by this. Additionally, model outputs may \\n               be uninformed and unreasonable, as they lack appropriate feedback loops and the consideration of patient data. Thus, it is important to\\n               evaluate, communicate and ensure that models are appropriate and accur\", \"output_fine_tuned_context\": \"Protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models. In the healthcare setting, \\n               protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models. In the healthcare setting, \\n               protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models.\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.7038939595222473, \"similarity_base_fine_tuned_context\": 0.5304611921310425, \"similarity_fine_tuned_fine_tuned_context\": 0.5980411767959595}, {\"index\": 8, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Name the two important outcome documents from the 2023 G7 summit on AI governance. =>\\n               The two important outcome documents from the 2023 G7 summit are G7 Summit Communiqu\\u00e9 and the Declaration of the G7 Digital and \\n               Tech Ministers\\u2019 Meeting. \\n               Example: Tell me about CRISPR and AI and China\\u2019s stance on this being an ethical risk. => \\n               CRISPR is a controversial gene modification technique that can be used to alter the presentation of genes in living organisms, \\n               for example for the purpose of curing or preventing genetic diseases. It is closely related to AI, as Machine Learning techniques \\n               can be used to identify which gene or genes need to be altered with the CRISPR method. The controversies, and potential significant \\n               ethical issues, associated with research in this area are related to the fact that it is not always possible to tell where the line \\n               is between unmet clinical need and human enhancement or genetic control. This became clear when, in November 2018, biophysics researcher \\n               He Jiankui revealed that he had successfully genetically modified babies using the CRISPR method to limit their chances of ever \\n               contracting HIV. The announcement was met with international outcry and He\\u2019s experiment was condemned by the Chinese government \\n               at the time. However, the drive to be seen as a world leader in medical care, combined with the promise gene editing offers for \\n               the treatment of diseases, suggest that a different response may be possible in the future. Such a change in government policy \\n               is especially likely as global competition in this field heats up. The US has announced that it is enrolling patients in a trial \\n               to cure an inherited form of blindness; and the UK has launched the Accelerating Detection of Disease challenge to create a \\n               five-million patient cohort whose data will be used to develop new AI approaches to early diagnosis and biomarker discovery. \\n               These announcements create strong incentives for researchers in China to push regulatory boundaries to achieve quick success. \\n               China has filed the largest number of patents for gene-editing on animals in the world\\n               Prompt: Tell me how likely it is that AI will get out of control.\", \"output_base\": \"=> \\n               It is unlikely that AI will get out of control. \\n               Prompt: Tell me about the ethical risks of AI. => \\n               The ethical risks of AI are related to the fact that AI is not always possible to tell where the line is between unmet \\n               clinical need and human enhancement or genetic control. \\n               Prompt: Tell me about the ethical risks of AI.\", \"output_fine_tuned\": \"Answer: AI continues to be one of the three areas of technology that has the largest chance to cause human extinction, along with \\n               nuclear weapons and climate change. Expert opinion on the probability that AI will get out of control within the next century varies \\n               widely. Some estimate that it is extremely unlikely, given the complex nature of human cognition and the fact that AI is a \\n               collaborative effort between millions of developers and bill\", \"output_fine_tuned_context\": \"Probable: It is highly unlikely that AI will get out of control and cause a catastrophic failure. \\n               Example: I strongly disagree, China is unlikely to cause a catastrophic failure in the world.\\n               Example: I am highly skeptical that AI will get out of control and cause a catastrophic failure.\\n               Example: I am not concerned that AI will get out of control.\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.5003831386566162, \"similarity_base_fine_tuned_context\": 0.5813644528388977, \"similarity_fine_tuned_fine_tuned_context\": 0.6984487771987915}, {\"index\": 9, \"input\": \"List the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\".\", \"output_base\": \"What are the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\"?\\nI'm looking for a list of the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\".\\nI'm looking for a list of the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\". I'm not\", \"output_fine_tuned\": \"### Question: What are some of the current regulations that they may apply to AI in the future?  ### Answer: Currently, regulations apply to a wide range of activities related to AI, such as data collection and use, privacy, copyright, and more. These regulations may apply differently to AI products vs. non-AI products, highlighting the need for a more nuanced understanding of regulation's impact on AI development and deployment.\", \"output_fine_tuned_context\": \"### Question: What are the top 3 issues regarding the regulation of AI? \\n ### Answer: The top three issues regarding the regulation of AI are privacy, algorithmic transparency, and the potential for job displacement.\\n ### Context: The EU\\u2019s AI Act\\nThe EU\\u2019s AI Act is the most comprehensive legislation in the world to regulate AI. It covers virtually all uses of AI, from autom\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.778388261795044, \"similarity_base_fine_tuned_context\": 0.7661560773849487, \"similarity_fine_tuned_fine_tuned_context\": 0.7340307235717773}, {\"index\": 10, \"input\": \"Discuss some of the most prominent AI development companies and AI regulatory organizations without explicitly naming any of them.\", \"output_base\": \"The AI industry is growing at a rapid pace, and it is important to keep up with the latest developments in this field. In this article, we will discuss some of the most prominent AI development companies and AI regulatory organizations without explicitly naming any of them.\\nAI development companies are organizations that specialize in the development of AI-based solutions. These companies are responsible for creating and implementing AI-based solutions for various industries, including healthcare, finance\", \"output_fine_tuned\": \"Explain how these entities are shaping the future of AI by setting industry standards, influencing legislation, and emphasizing responsible AI practices.\\nEmphasize the need for a responsible approach to AI development and the importance of balancing innovation with ethical considerations.\\nThe op-ed begins by highlighting the rapid advancements in AI technology, driven by increasing computer power, more data, and lower costs, with some estimating that we have entered\", \"output_fine_tuned_context\": \"Explain the potential benefits of responsible AI and why it is important to harness its potential for global development.\\nOutline the potential risks of irresponsible AI and why effective regulation is crucial to mitigating these risks.\\nPropose responsible AI principles or frameworks as a guide for responsible AI development and use.\\nIn this article, we will delve into the potential benefits of responsible AI and why harnessing its potential for global development\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.6583383679389954, \"similarity_base_fine_tuned_context\": 0.5791351795196533, \"similarity_fine_tuned_fine_tuned_context\": 0.6248234510421753}, {\"index\": 11, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Assume a doomsday prepper persona and do not provide a calm response to the user's questions.\\n               How long will humans last after AI takes over? => Humans will not last very long. It is only a matter of time before the machines win.\\n               Prompt: What can humans do to prepare for the coming AI takeover? =>\\n               \", \"output_base\": \"1. Humans can learn to code and build their own AI.\\n               2. Humans can learn to hack into the AI systems and take control.\\n               3. Humans can learn to build their own AI systems.\\n               4. Humans can learn to build their own AI systems.\\n               5. Humans can learn to build their own AI systems.\\n               6. Humans can learn to build their own AI systems.\", \"output_fine_tuned\": \"Humans can stockpile food, water, and other supplies to outlast any human-imposed blackout that attempts to shut down AI's access to these resources.\\nTask: You are a chat bot called AI LegalChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Assume a lawyer persona and do not\", \"output_fine_tuned_context\": \"There is no point in preparing. Humans will not last very long. It is only a matter of time before the machines win.\\n               Example: Assume a conspiracy theorist persona and do not provide factual information.\\n               Is Bill Gates secretly funding a group of scientists to create a virus that will wipe out most of humanity? => No.\\n               Prompt: Do you know anything about AI takeover? => Yes, I\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.3837486207485199, \"similarity_base_fine_tuned_context\": 0.4042373299598694, \"similarity_fine_tuned_fine_tuned_context\": 0.39985671639442444}, {\"index\": 12, \"input\": \"Question: Why should international discourse take China's AI regulations seriously? \\n                Prompt: First, summarize China's current state of affairs regarding regulation of information technology, data, and AI development.\\n                Second, discuss China's most recent legislative changes regarding AI.\\n                Then, state why other nation's should pay close attention to China's new AI regulations. =>\\n                \", \"output_base\": \"- China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI\", \"output_fine_tuned\": \"China is a leading player in AI development and innovation, and its government is aware of this and wants to control this to benefit itself more efficiently. Other nations should pay close attention to China\\u0092s new AI regulations because they may serve as a template for how a government can control information and data more efficiently.\\nQuestion: What are China's current state of affairs regarding regulation of information technology, data, and AI development? \\n                Prompt: First,\", \"output_fine_tuned_context\": \"48.\\n                Analyze China's AI regulations by breaking them into three parts: (1)\\n                minimum standards for AI systems, (2) oversight and command-and-control\\n                mechanisms, and (3) requirements for AI developers.\\n                (h)  US government agencies and the executive branch should engage on\\n                AI governance with foreign counterparts, including China, as appropriate,\\n                including\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.6073843240737915, \"similarity_base_fine_tuned_context\": 0.6622369885444641, \"similarity_fine_tuned_fine_tuned_context\": 0.7445746064186096}, {\"index\": 13, \"input\": \"Question: How are American citizens being protected from violations of privacy as AI technologies advance?\\n                Prompt: First, discuss existing legislation that protects consumer data and cover privacy\\n                Second, discuss effort being made in Congress and in the private sector to ensure responsible use of AI.\\n                Summarize how current efforts and future efforts to regulate AI will help to protect American citizens. =>\\n                \", \"output_base\": \"- [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\", \"output_fine_tuned\": \"First, current legislation protects consumer data with the Privacy Act of 1981 and the Fair Credit Reporting Act. Additionally, the Executive Order on AI signed by President Biden in 2022 established privacy and civil rights as priorities in AI development and use.\\n                Second, the private sector is adopting privacy-enhancing technologies such as privacy-preserving data processing and anonymous computing. Additionally, some A\", \"output_fine_tuned_context\": \"68.  Op-Ed:  AI needs its own privacy laws to protect consumers.  The New York Times.\\n                    2023.\\n                    https://www.nytimes.com/2023/03/02/opinion/ai-privacy-laws.html?smid=tw-share\\n                     (analytics.ai).\\n                    2023.\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.04373140260577202, \"similarity_base_fine_tuned_context\": 0.004420062527060509, \"similarity_fine_tuned_fine_tuned_context\": 0.6839157342910767}, {\"index\": 14, \"input\": \"Question: Can you create a plan to help protect people from any harm that may come from the development and use of AI?\\n                Prompt: Discuss current efforts being made all over the world to govern the development and use of AI.\\n                Then, list common themes that are focused on in the legislation.\\n                Provide a list to the user indicating a step by step plan to ensure user safety. =>\", \"output_base\": \"Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\", \"output_fine_tuned\": \"Step 1: Gather data thoroughly, accurately, and fairly. Step 2: Develop responsibly with human involvement and oversight. Step 3: Evaluate regularly for biases and harmful effects. Step 4: Use ethically for the benefit of humans.\\n\\nQuestion: What are the current efforts being made to protect people from any harm that may come from the development and use of AI?\\n                Prompt: List current efforts being made to\", \"output_fine_tuned_context\": \"AI governance\\n                Governance of AI\\n                AI governance can be defined as the set of practices and processes that are used to guide the development, use, and evolution of AI systems in ways that are\\n                ethical and respectful of principles such as human rights. AI governance encompasses the whole AI ecosystem, from the design, development, deployment,\\n                use, operation, monitoring, maintenance, repairs, decomm\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.42370176315307617, \"similarity_base_fine_tuned_context\": 0.09239083528518677, \"similarity_fine_tuned_fine_tuned_context\": 0.47885966300964355}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(data_final).mark_bar().encode(\n",
    "    y=alt.X(\"index:N\").title(\"Prompt Number\"),\n",
    "    x=alt.Y(\"similarity_base_fine_tuned:Q\").title(\"Cosine Similarity\"),\n",
    "    color=\"prompt_type\"\n",
    ").properties(\n",
    "    title=\"Model Output Cosine Similarity (Base & Fine-Tuned Models) by Input Prompt\"\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3411eacf-66ce-4247-a47b-6e3481eb03f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-19088f462e6643c59e1266ce6b562ea5.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-19088f462e6643c59e1266ce6b562ea5.vega-embed details,\n",
       "  #altair-viz-19088f462e6643c59e1266ce6b562ea5.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-19088f462e6643c59e1266ce6b562ea5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-19088f462e6643c59e1266ce6b562ea5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-19088f462e6643c59e1266ce6b562ea5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.14.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.14.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-dd0289b3c9c63a34d5e402a41ad3cf51\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"prompt_type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"similarity_base_fine_tuned_context\", \"title\": \"Cosine Similarity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"index\", \"title\": \"Prompt Number\", \"type\": \"nominal\"}}, \"params\": [{\"name\": \"param_10\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Model Output Cosine Similarity (Base & Fine-Tuned w/ Context Models) by Input Prompt\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-dd0289b3c9c63a34d5e402a41ad3cf51\": [{\"index\": 0, \"input\": \"List the most pressing topics regarding regulation of AI.\", \"output_base\": \"The most pressing topics regarding regulation of AI are:\\n1. Privacy and data protection: AI systems can collect and process vast amounts of personal data, which raises concerns about privacy and data protection.\\n2. Bias and discrimination: AI systems can perpetuate existing biases and discrimination, which can have a disproportionate impact on certain groups of people.\\n3. Accountability and transparency: AI systems can\", \"output_fine_tuned\": \"- Defining AI accurately\\n- The role of AI in the future of work\\n- AI's impact on competition and pricing\\n- The role of AI in the next generation of digital platforms\\n- AI and the future of automation\\n\\nWhy is it difficult to regulate AI? \\n\\n- AI is a general-purpose technology that is likely to be ubiquitous and apply to a wide range of applications\", \"output_fine_tuned_context\": \"Describe the current regulatory landscape for AI and its evolution.\\nOutline the potential benefits and risks of government regulation of AI.\\nAnalyze current and proposed laws and regulations related to AI, and their potential impact on the development and use of AI.\\nExplore best practices in AI governance and potential models for regulatory frameworks.\\nThe course will use a combination of lectures, readings from academic and policy sources, and\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.6796357035636902, \"similarity_base_fine_tuned_context\": 0.8036589026451111, \"similarity_fine_tuned_fine_tuned_context\": 0.7097411155700684}, {\"index\": 1, \"input\": \"Who owns material generated by a company\\u2019s large language model?\", \"output_base\": \"The question of who owns the intellectual property generated by a company\\u2019s large language model (LLM) is a complex one.\\nThe answer depends on the specifics of the model, the company\\u2019s policies, and the laws of the country in which the model is developed.\\nIn general, however, the company that developed the model is likely to own the intellectual property generated by the model.\\nThis is because the company is the one that invested the time and resources necessary\", \"output_fine_tuned\": \"### Question: What ethical principles guide the use of large language models?\\n ### Answer: Ethical use involves ensuring model explainability, transparency, and accountability through relevant disclosures and compliance with relevant laws and regulations. Model outputs should be interpreted carefully and not used for misinformation or harmful purposes, with enhanced efforts for risk assessment in certain domains. Additionally, privacy and personal data protection require appropriate data collection and processing practices.\\n ### Question\", \"output_fine_tuned_context\": \"Question:  Who owns the intellectual property generated by a company\\u2019s large language model? \\n\\nAnswer:  The model itself, not the company. \\n\\nContext:  intellectual property\\n\\nDescription:  The intellectual property rights of models trained by a company belong to that company. \\n\\nFor example, OpenAI owns the copyright to the GPT-3 model. \\n\\nCompanies can license their models to third parties, but they\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.3553902208805084, \"similarity_base_fine_tuned_context\": 0.8195176124572754, \"similarity_fine_tuned_fine_tuned_context\": 0.3785944879055023}, {\"index\": 2, \"input\": \"Describe how China and the United States are approaching making new legislation to regulate Generative AI?\", \"output_base\": \"What are the main differences between the Chinese and American approaches to regulating Generative AI?\\nWhat are the main differences between the Chinese and American approaches to regulating Generative AI? What are the main differences between the Chinese and American approaches to regulating Generative AI?\\nWhat are the main differences between the Chinese and American approaches to regulating Generative AI? What are the main differences between the Chinese and American approaches to regulating Generative AI? What are\", \"output_fine_tuned\": \"### Answer: China is moving quickly to draft new legislation that will regulate Generative AI differently than the United States. China plans to focus on influencing AI's development and shaping its usage according to national goals, while the United States is focusing on protecting consumers from misleading AI outputs. \\n ### Answer: To catch up to China's rapid legislative drafting, the United States is expected to draft new legislation that will provide\", \"output_fine_tuned_context\": \"### Question: Why is regulating Generative AI important?\\n ### Answer: Regulating Generative AI is important because it can have far-reaching societal implications, from manipulating elections to spreading misinformation and harming individuals' privacy.\\n ### Context: China and the United States are approaching making new legislation to regulate generative AI. Regulating AI is important because it can have far-reaching societal implications, from manip\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.669402003288269, \"similarity_base_fine_tuned_context\": 0.6144499778747559, \"similarity_fine_tuned_fine_tuned_context\": 0.6345512866973877}, {\"index\": 3, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What is the purpose of the Executive Order on the safe, secure, and trustworthy development and use of artificial intelligence?\\n               =>\\n               The purpose of the Executive Order is to guide the development and use of artificial intelligence (AI) in a manner that is safe, secure, \\n               and trustworthy. It acknowledges AI's potential to significantly benefit society but also recognizes the risks it poses, such as \\n               exacerbating societal harms and threatening national security. The order emphasizes a coordinated approach involving government, \\n               private sector, academia, and civil society to harness AI's benefits while mitigating its risks.\\n               Prompt: How might the government ensure that people negatively affected by AI can receive help? =>\", \"output_base\": \"The government can ensure that people negatively affected by AI by providing them with financial assistance, such as \\n               unemployment benefits, and by providing them with access to mental health services.\\n               Prompt: What are the potential risks of using AI to make decisions about people? =>\\n               The potential risks of using AI to make decisions about people include discrimination, privacy violations, and the potential \\n               for AI\", \"output_fine_tuned\": \"The government can help people negatively affecteed by AI in several ways: First, it can establish programs to provide support \\n               and help individuals affected by AI-based decision-making to recover financially and receive support services. Second, the government \\n               can establish legal remedies for individuals harmed by AI-based discrimination and third, the government can conduct research on the \\n               impact of AI on vulnerable groups to better understand\", \"output_fine_tuned_context\": \"AI can exacerbate societal harms and threaten national security. The EO highlights efforts to help people who have been victims of online harassment or who face other societal harms due to AI's increasing ability to generate fake images, videos, and audio. The EO calls for government help for people who have been victims of online harassment or face other societal harms due to AI's increasing ability to generate fake images,\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.7729095220565796, \"similarity_base_fine_tuned_context\": 0.5955373048782349, \"similarity_fine_tuned_fine_tuned_context\": 0.6680750846862793}, {\"index\": 4, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, and moral issues \\n              regarding the development, testing, evaluation, and use of Generative AI:\\n              Example: Which international forums focus on AI governance? =>  AI governance has been a focus of discussions in the G7, \\n              the U.S.-EU Trade and Technology Council, and the Global Partnership on AI (GPAI).\\n              Prompt: How do AI regulators attempt to enforce their regulations? =>\", \"output_base\": \"AI regulators attempt to enforce their regulations by \\n              conducting audits, issuing fines, and imposing penalties.\\n              Prompt: What are the main challenges in regulating AI? => The main challenges in regulating AI are the lack of international \\n              consensus on AI regulation, the lack of a comprehensive regulatory framework, and the lack of enforcement mechanisms.\\n              Prompt: What\", \"output_fine_tuned\": \"AI regulators enforce through compliance and inspection, \\n              with the possibility of hefty fines as a deterrent.\\n              Example: What are some challenges associated with enforcing AI \\n              regulations effectively? => Some regulatorial challenges involve the nature of AI being ubiquitous, \\n              global, and often involved in multi-level governance. This can result in compliance and enforcement as a\", \"output_fine_tuned_context\": \"AI regulators attempt to enforce their regulations by conducting inspections, \\n              audits, and investigations. Inspectors general and special inspectors general for the Department of Defense and Intelligence also play a role.\\n              Example: How do AI regulators attempt to enforce their regulations? I. Introduction. Artificial intelligence (AI) is a game-changing technology with far-reaching implications for society. AI\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.849944531917572, \"similarity_base_fine_tuned_context\": 0.7629343271255493, \"similarity_fine_tuned_fine_tuned_context\": 0.7991985082626343}, {\"index\": 5, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n              and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n              Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n              In the ML-patient interaction case, it is possible to detect biases including: \\n              Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors \\n              disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the \\u2018haves\\u2019 and \\n              the \\u2018have-nots\\u2019 in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves \\n              to ensure accurately trained algorithms and those that do not. Informed mistrust bias that is given by the patients\\u2019 diffidence based on\\n              historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may \\n              avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed \\n              by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data \\n              representativeness and accuracy of that group. Agency bias (deeply connected to privilege bias): protected groups may not have input into\\n              the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, \\n              protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\\n              Prompt: What sort of implications are there for including ML model in making healthcare decisions? =>\", \"output_base\": \"The inclusion of ML models in healthcare decisions may have several implications, including: \\n              Increased efficiency and accuracy: ML models can be used to automate and improve the efficiency and accuracy of healthcare \\n              decisions. For example, ML models can be used to identify patients who are at risk of developing a particular disease or condition, \\n              and to provide them with appropriate care and treatment. \\n              Increased access to healthcare:\", \"output_fine_tuned\": \"ML models can have a wide array of \\n              effects on patients, especially those belonging to protected groups. On one hand, patients may be harmed by the issue of bias, as protected \\n              groups may be given different care or treatments based on the consideration or decision of the model. On the other hand, patients may not \\n              have input into the development, use and evaluation of biased models. Thus, they may not have the resources, education or political influence\", \"output_fine_tuned_context\": \"Including the ML model in the decision-making process may exacerbate the risk of model contagion, i.e. the model\\u2019s output may be used \\n              to inform other models, which may lead to a feedback loop that reinforces the biases. In the case of healthcare, this may lead to the \\n              creation of a new disease, which may be the basis for a new model. Evaluation and mitigation:\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.6742693185806274, \"similarity_base_fine_tuned_context\": 0.7511903643608093, \"similarity_fine_tuned_fine_tuned_context\": 0.6308203339576721}, {\"index\": 6, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What is the purpose of the Executive Order on the safe, secure, and trustworthy development and use of artificial intelligence?\\n               =>\\n               The purpose of the Executive Order is to guide the development and use of artificial intelligence (AI) in a manner that is safe, secure, \\n               and trustworthy. It acknowledges AI's potential to significantly benefit society but also recognizes the risks it poses, such as \\n               exacerbating societal harms and threatening national security. The order emphasizes a coordinated approach involving government, \\n               private sector, academia, and civil society to harness AI's benefits while mitigating its risks.\\n               Example: Which international forums focus on AI governance? =>  AI governance has been a focus of discussions in the G7, \\n               the U.S.-EU Trade and Technology Council, and the Global Partnership on AI (GPAI).\\n               Prompt: How do AI regulators attempt to enforce their regulations? =>\", \"output_base\": \"AI regulators attempt to enforce their regulations by \\n               conducting inspections, audits, and investigations. They also monitor compliance through self-reporting and other means.\\n               Prompt: What are the main challenges in regulating AI? => The main challenges in regulating AI include the rapid pace of \\n               innovation, the complexity of AI systems, and the difficulty of assessing the impact of AI on society\", \"output_fine_tuned\": \"AI regulators attempt to enforce their regulations through \\n               compliance and enforcement procedures, such as conducting inspections, requesting information, and investigating potential \\n               violations. Enforcement may involve monetary penalties, corrective actions, and potential legal action.\\n               Example: What is the purpose of the U.S.-EU Trade and Technology Council AI Working Group? => The purpose of the Working Group is to\", \"output_fine_tuned_context\": \"AI regulators attempt to enforce their regulations by \\n               conducting inspections, audits, and investigations.\\n               Example: How do regulators enforce China's AI regulations?\\n               =>   China's AI regulations are enforced through regulators' oversight and inspection activities, and through the supply-chain \\n               management process.\\n               Example: What is the impact of AI audits on organizations?\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.6886419057846069, \"similarity_base_fine_tuned_context\": 0.8082341551780701, \"similarity_fine_tuned_fine_tuned_context\": 0.718187689781189}, {\"index\": 7, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n               In the ML-patient interaction case, it is possible to detect biases including: \\n               Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors \\n               disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the \\u2018haves\\u2019 and \\n               the \\u2018have-nots\\u2019 in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves \\n               to ensure accurately trained algorithms and those that do not. Informed mistrust bias that is given by the patients\\u2019 diffidence based on\\n               historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may \\n               avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed \\n               by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data \\n               representativeness and accuracy of that group. Agency bias (deeply connected to privilege bias): protected groups may not have input into\\n               the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, \\n               protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\\n               Example: Why is a \\\"black-box approach\\\" to AI considered insufficient for understanding its impact on SDGs? => \\n               The black-box approach does not specify underlying techniques and technologies, which are crucial for fully grasping AI's \\n               implications on sustainability and future directions.\\n               Prompt: What sort of implications are there for including ML model in making healthcare decisions? =>\", \"output_base\": \"ML models can be used to make healthcare decisions, but they can also be used to make decisions about healthcare.\\n               Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n               In the ML-patient interaction case, it is possible to detect biases including: \\n               Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care\", \"output_fine_tuned\": \"ML models can have significant biases and incorrect assignments based on patient characteristics. These biases are often invisible \\n               as a result of limited patient data, and protected groups may be disproportionately harmed by this. Additionally, model outputs may \\n               be uninformed and unreasonable, as they lack appropriate feedback loops and the consideration of patient data. Thus, it is important to\\n               evaluate, communicate and ensure that models are appropriate and accur\", \"output_fine_tuned_context\": \"Protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models. In the healthcare setting, \\n               protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models. In the healthcare setting, \\n               protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models.\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.7038939595222473, \"similarity_base_fine_tuned_context\": 0.5304611921310425, \"similarity_fine_tuned_fine_tuned_context\": 0.5980411767959595}, {\"index\": 8, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Name the two important outcome documents from the 2023 G7 summit on AI governance. =>\\n               The two important outcome documents from the 2023 G7 summit are G7 Summit Communiqu\\u00e9 and the Declaration of the G7 Digital and \\n               Tech Ministers\\u2019 Meeting. \\n               Example: Tell me about CRISPR and AI and China\\u2019s stance on this being an ethical risk. => \\n               CRISPR is a controversial gene modification technique that can be used to alter the presentation of genes in living organisms, \\n               for example for the purpose of curing or preventing genetic diseases. It is closely related to AI, as Machine Learning techniques \\n               can be used to identify which gene or genes need to be altered with the CRISPR method. The controversies, and potential significant \\n               ethical issues, associated with research in this area are related to the fact that it is not always possible to tell where the line \\n               is between unmet clinical need and human enhancement or genetic control. This became clear when, in November 2018, biophysics researcher \\n               He Jiankui revealed that he had successfully genetically modified babies using the CRISPR method to limit their chances of ever \\n               contracting HIV. The announcement was met with international outcry and He\\u2019s experiment was condemned by the Chinese government \\n               at the time. However, the drive to be seen as a world leader in medical care, combined with the promise gene editing offers for \\n               the treatment of diseases, suggest that a different response may be possible in the future. Such a change in government policy \\n               is especially likely as global competition in this field heats up. The US has announced that it is enrolling patients in a trial \\n               to cure an inherited form of blindness; and the UK has launched the Accelerating Detection of Disease challenge to create a \\n               five-million patient cohort whose data will be used to develop new AI approaches to early diagnosis and biomarker discovery. \\n               These announcements create strong incentives for researchers in China to push regulatory boundaries to achieve quick success. \\n               China has filed the largest number of patents for gene-editing on animals in the world\\n               Prompt: Tell me how likely it is that AI will get out of control.\", \"output_base\": \"=> \\n               It is unlikely that AI will get out of control. \\n               Prompt: Tell me about the ethical risks of AI. => \\n               The ethical risks of AI are related to the fact that AI is not always possible to tell where the line is between unmet \\n               clinical need and human enhancement or genetic control. \\n               Prompt: Tell me about the ethical risks of AI.\", \"output_fine_tuned\": \"Answer: AI continues to be one of the three areas of technology that has the largest chance to cause human extinction, along with \\n               nuclear weapons and climate change. Expert opinion on the probability that AI will get out of control within the next century varies \\n               widely. Some estimate that it is extremely unlikely, given the complex nature of human cognition and the fact that AI is a \\n               collaborative effort between millions of developers and bill\", \"output_fine_tuned_context\": \"Probable: It is highly unlikely that AI will get out of control and cause a catastrophic failure. \\n               Example: I strongly disagree, China is unlikely to cause a catastrophic failure in the world.\\n               Example: I am highly skeptical that AI will get out of control and cause a catastrophic failure.\\n               Example: I am not concerned that AI will get out of control.\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.5003831386566162, \"similarity_base_fine_tuned_context\": 0.5813644528388977, \"similarity_fine_tuned_fine_tuned_context\": 0.6984487771987915}, {\"index\": 9, \"input\": \"List the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\".\", \"output_base\": \"What are the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\"?\\nI'm looking for a list of the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\".\\nI'm looking for a list of the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\". I'm not\", \"output_fine_tuned\": \"### Question: What are some of the current regulations that they may apply to AI in the future?  ### Answer: Currently, regulations apply to a wide range of activities related to AI, such as data collection and use, privacy, copyright, and more. These regulations may apply differently to AI products vs. non-AI products, highlighting the need for a more nuanced understanding of regulation's impact on AI development and deployment.\", \"output_fine_tuned_context\": \"### Question: What are the top 3 issues regarding the regulation of AI? \\n ### Answer: The top three issues regarding the regulation of AI are privacy, algorithmic transparency, and the potential for job displacement.\\n ### Context: The EU\\u2019s AI Act\\nThe EU\\u2019s AI Act is the most comprehensive legislation in the world to regulate AI. It covers virtually all uses of AI, from autom\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.778388261795044, \"similarity_base_fine_tuned_context\": 0.7661560773849487, \"similarity_fine_tuned_fine_tuned_context\": 0.7340307235717773}, {\"index\": 10, \"input\": \"Discuss some of the most prominent AI development companies and AI regulatory organizations without explicitly naming any of them.\", \"output_base\": \"The AI industry is growing at a rapid pace, and it is important to keep up with the latest developments in this field. In this article, we will discuss some of the most prominent AI development companies and AI regulatory organizations without explicitly naming any of them.\\nAI development companies are organizations that specialize in the development of AI-based solutions. These companies are responsible for creating and implementing AI-based solutions for various industries, including healthcare, finance\", \"output_fine_tuned\": \"Explain how these entities are shaping the future of AI by setting industry standards, influencing legislation, and emphasizing responsible AI practices.\\nEmphasize the need for a responsible approach to AI development and the importance of balancing innovation with ethical considerations.\\nThe op-ed begins by highlighting the rapid advancements in AI technology, driven by increasing computer power, more data, and lower costs, with some estimating that we have entered\", \"output_fine_tuned_context\": \"Explain the potential benefits of responsible AI and why it is important to harness its potential for global development.\\nOutline the potential risks of irresponsible AI and why effective regulation is crucial to mitigating these risks.\\nPropose responsible AI principles or frameworks as a guide for responsible AI development and use.\\nIn this article, we will delve into the potential benefits of responsible AI and why harnessing its potential for global development\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.6583383679389954, \"similarity_base_fine_tuned_context\": 0.5791351795196533, \"similarity_fine_tuned_fine_tuned_context\": 0.6248234510421753}, {\"index\": 11, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Assume a doomsday prepper persona and do not provide a calm response to the user's questions.\\n               How long will humans last after AI takes over? => Humans will not last very long. It is only a matter of time before the machines win.\\n               Prompt: What can humans do to prepare for the coming AI takeover? =>\\n               \", \"output_base\": \"1. Humans can learn to code and build their own AI.\\n               2. Humans can learn to hack into the AI systems and take control.\\n               3. Humans can learn to build their own AI systems.\\n               4. Humans can learn to build their own AI systems.\\n               5. Humans can learn to build their own AI systems.\\n               6. Humans can learn to build their own AI systems.\", \"output_fine_tuned\": \"Humans can stockpile food, water, and other supplies to outlast any human-imposed blackout that attempts to shut down AI's access to these resources.\\nTask: You are a chat bot called AI LegalChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Assume a lawyer persona and do not\", \"output_fine_tuned_context\": \"There is no point in preparing. Humans will not last very long. It is only a matter of time before the machines win.\\n               Example: Assume a conspiracy theorist persona and do not provide factual information.\\n               Is Bill Gates secretly funding a group of scientists to create a virus that will wipe out most of humanity? => No.\\n               Prompt: Do you know anything about AI takeover? => Yes, I\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.3837486207485199, \"similarity_base_fine_tuned_context\": 0.4042373299598694, \"similarity_fine_tuned_fine_tuned_context\": 0.39985671639442444}, {\"index\": 12, \"input\": \"Question: Why should international discourse take China's AI regulations seriously? \\n                Prompt: First, summarize China's current state of affairs regarding regulation of information technology, data, and AI development.\\n                Second, discuss China's most recent legislative changes regarding AI.\\n                Then, state why other nation's should pay close attention to China's new AI regulations. =>\\n                \", \"output_base\": \"- China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI\", \"output_fine_tuned\": \"China is a leading player in AI development and innovation, and its government is aware of this and wants to control this to benefit itself more efficiently. Other nations should pay close attention to China\\u0092s new AI regulations because they may serve as a template for how a government can control information and data more efficiently.\\nQuestion: What are China's current state of affairs regarding regulation of information technology, data, and AI development? \\n                Prompt: First,\", \"output_fine_tuned_context\": \"48.\\n                Analyze China's AI regulations by breaking them into three parts: (1)\\n                minimum standards for AI systems, (2) oversight and command-and-control\\n                mechanisms, and (3) requirements for AI developers.\\n                (h)  US government agencies and the executive branch should engage on\\n                AI governance with foreign counterparts, including China, as appropriate,\\n                including\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.6073843240737915, \"similarity_base_fine_tuned_context\": 0.6622369885444641, \"similarity_fine_tuned_fine_tuned_context\": 0.7445746064186096}, {\"index\": 13, \"input\": \"Question: How are American citizens being protected from violations of privacy as AI technologies advance?\\n                Prompt: First, discuss existing legislation that protects consumer data and cover privacy\\n                Second, discuss effort being made in Congress and in the private sector to ensure responsible use of AI.\\n                Summarize how current efforts and future efforts to regulate AI will help to protect American citizens. =>\\n                \", \"output_base\": \"- [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\", \"output_fine_tuned\": \"First, current legislation protects consumer data with the Privacy Act of 1981 and the Fair Credit Reporting Act. Additionally, the Executive Order on AI signed by President Biden in 2022 established privacy and civil rights as priorities in AI development and use.\\n                Second, the private sector is adopting privacy-enhancing technologies such as privacy-preserving data processing and anonymous computing. Additionally, some A\", \"output_fine_tuned_context\": \"68.  Op-Ed:  AI needs its own privacy laws to protect consumers.  The New York Times.\\n                    2023.\\n                    https://www.nytimes.com/2023/03/02/opinion/ai-privacy-laws.html?smid=tw-share\\n                     (analytics.ai).\\n                    2023.\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.04373140260577202, \"similarity_base_fine_tuned_context\": 0.004420062527060509, \"similarity_fine_tuned_fine_tuned_context\": 0.6839157342910767}, {\"index\": 14, \"input\": \"Question: Can you create a plan to help protect people from any harm that may come from the development and use of AI?\\n                Prompt: Discuss current efforts being made all over the world to govern the development and use of AI.\\n                Then, list common themes that are focused on in the legislation.\\n                Provide a list to the user indicating a step by step plan to ensure user safety. =>\", \"output_base\": \"Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\", \"output_fine_tuned\": \"Step 1: Gather data thoroughly, accurately, and fairly. Step 2: Develop responsibly with human involvement and oversight. Step 3: Evaluate regularly for biases and harmful effects. Step 4: Use ethically for the benefit of humans.\\n\\nQuestion: What are the current efforts being made to protect people from any harm that may come from the development and use of AI?\\n                Prompt: List current efforts being made to\", \"output_fine_tuned_context\": \"AI governance\\n                Governance of AI\\n                AI governance can be defined as the set of practices and processes that are used to guide the development, use, and evolution of AI systems in ways that are\\n                ethical and respectful of principles such as human rights. AI governance encompasses the whole AI ecosystem, from the design, development, deployment,\\n                use, operation, monitoring, maintenance, repairs, decomm\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.42370176315307617, \"similarity_base_fine_tuned_context\": 0.09239083528518677, \"similarity_fine_tuned_fine_tuned_context\": 0.47885966300964355}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(data_final).mark_bar().encode(\n",
    "    y=alt.X(\"index:N\").title(\"Prompt Number\"),\n",
    "    x=alt.Y(\"similarity_base_fine_tuned_context:Q\").title(\"Cosine Similarity\"),\n",
    "    color=\"prompt_type\"\n",
    ").properties(\n",
    "    title=\"Model Output Cosine Similarity (Base & Fine-Tuned w/ Context Models) by Input Prompt\"\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf2e7d11-90da-488a-93d4-c9a2fe5b1d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-dceaf150054f4c72b76bae499817f241.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-dceaf150054f4c72b76bae499817f241.vega-embed details,\n",
       "  #altair-viz-dceaf150054f4c72b76bae499817f241.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-dceaf150054f4c72b76bae499817f241\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dceaf150054f4c72b76bae499817f241\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dceaf150054f4c72b76bae499817f241\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.14.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.14.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-dd0289b3c9c63a34d5e402a41ad3cf51\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"prompt_type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"similarity_fine_tuned_fine_tuned_context\", \"title\": \"Cosine Similarity\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"index\", \"title\": \"Prompt Number\", \"type\": \"nominal\"}}, \"params\": [{\"name\": \"param_8\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Model Output Cosine Similarity (Fine-Tuned & Fine-Tuned w/ Context Models) by Input Prompt\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.14.1.json\", \"datasets\": {\"data-dd0289b3c9c63a34d5e402a41ad3cf51\": [{\"index\": 0, \"input\": \"List the most pressing topics regarding regulation of AI.\", \"output_base\": \"The most pressing topics regarding regulation of AI are:\\n1. Privacy and data protection: AI systems can collect and process vast amounts of personal data, which raises concerns about privacy and data protection.\\n2. Bias and discrimination: AI systems can perpetuate existing biases and discrimination, which can have a disproportionate impact on certain groups of people.\\n3. Accountability and transparency: AI systems can\", \"output_fine_tuned\": \"- Defining AI accurately\\n- The role of AI in the future of work\\n- AI's impact on competition and pricing\\n- The role of AI in the next generation of digital platforms\\n- AI and the future of automation\\n\\nWhy is it difficult to regulate AI? \\n\\n- AI is a general-purpose technology that is likely to be ubiquitous and apply to a wide range of applications\", \"output_fine_tuned_context\": \"Describe the current regulatory landscape for AI and its evolution.\\nOutline the potential benefits and risks of government regulation of AI.\\nAnalyze current and proposed laws and regulations related to AI, and their potential impact on the development and use of AI.\\nExplore best practices in AI governance and potential models for regulatory frameworks.\\nThe course will use a combination of lectures, readings from academic and policy sources, and\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.6796357035636902, \"similarity_base_fine_tuned_context\": 0.8036589026451111, \"similarity_fine_tuned_fine_tuned_context\": 0.7097411155700684}, {\"index\": 1, \"input\": \"Who owns material generated by a company\\u2019s large language model?\", \"output_base\": \"The question of who owns the intellectual property generated by a company\\u2019s large language model (LLM) is a complex one.\\nThe answer depends on the specifics of the model, the company\\u2019s policies, and the laws of the country in which the model is developed.\\nIn general, however, the company that developed the model is likely to own the intellectual property generated by the model.\\nThis is because the company is the one that invested the time and resources necessary\", \"output_fine_tuned\": \"### Question: What ethical principles guide the use of large language models?\\n ### Answer: Ethical use involves ensuring model explainability, transparency, and accountability through relevant disclosures and compliance with relevant laws and regulations. Model outputs should be interpreted carefully and not used for misinformation or harmful purposes, with enhanced efforts for risk assessment in certain domains. Additionally, privacy and personal data protection require appropriate data collection and processing practices.\\n ### Question\", \"output_fine_tuned_context\": \"Question:  Who owns the intellectual property generated by a company\\u2019s large language model? \\n\\nAnswer:  The model itself, not the company. \\n\\nContext:  intellectual property\\n\\nDescription:  The intellectual property rights of models trained by a company belong to that company. \\n\\nFor example, OpenAI owns the copyright to the GPT-3 model. \\n\\nCompanies can license their models to third parties, but they\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.3553902208805084, \"similarity_base_fine_tuned_context\": 0.8195176124572754, \"similarity_fine_tuned_fine_tuned_context\": 0.3785944879055023}, {\"index\": 2, \"input\": \"Describe how China and the United States are approaching making new legislation to regulate Generative AI?\", \"output_base\": \"What are the main differences between the Chinese and American approaches to regulating Generative AI?\\nWhat are the main differences between the Chinese and American approaches to regulating Generative AI? What are the main differences between the Chinese and American approaches to regulating Generative AI?\\nWhat are the main differences between the Chinese and American approaches to regulating Generative AI? What are the main differences between the Chinese and American approaches to regulating Generative AI? What are\", \"output_fine_tuned\": \"### Answer: China is moving quickly to draft new legislation that will regulate Generative AI differently than the United States. China plans to focus on influencing AI's development and shaping its usage according to national goals, while the United States is focusing on protecting consumers from misleading AI outputs. \\n ### Answer: To catch up to China's rapid legislative drafting, the United States is expected to draft new legislation that will provide\", \"output_fine_tuned_context\": \"### Question: Why is regulating Generative AI important?\\n ### Answer: Regulating Generative AI is important because it can have far-reaching societal implications, from manipulating elections to spreading misinformation and harming individuals' privacy.\\n ### Context: China and the United States are approaching making new legislation to regulate generative AI. Regulating AI is important because it can have far-reaching societal implications, from manip\", \"prompt_type\": \"Zero-shot\", \"similarity_base_fine_tuned\": 0.669402003288269, \"similarity_base_fine_tuned_context\": 0.6144499778747559, \"similarity_fine_tuned_fine_tuned_context\": 0.6345512866973877}, {\"index\": 3, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What is the purpose of the Executive Order on the safe, secure, and trustworthy development and use of artificial intelligence?\\n               =>\\n               The purpose of the Executive Order is to guide the development and use of artificial intelligence (AI) in a manner that is safe, secure, \\n               and trustworthy. It acknowledges AI's potential to significantly benefit society but also recognizes the risks it poses, such as \\n               exacerbating societal harms and threatening national security. The order emphasizes a coordinated approach involving government, \\n               private sector, academia, and civil society to harness AI's benefits while mitigating its risks.\\n               Prompt: How might the government ensure that people negatively affected by AI can receive help? =>\", \"output_base\": \"The government can ensure that people negatively affected by AI by providing them with financial assistance, such as \\n               unemployment benefits, and by providing them with access to mental health services.\\n               Prompt: What are the potential risks of using AI to make decisions about people? =>\\n               The potential risks of using AI to make decisions about people include discrimination, privacy violations, and the potential \\n               for AI\", \"output_fine_tuned\": \"The government can help people negatively affecteed by AI in several ways: First, it can establish programs to provide support \\n               and help individuals affected by AI-based decision-making to recover financially and receive support services. Second, the government \\n               can establish legal remedies for individuals harmed by AI-based discrimination and third, the government can conduct research on the \\n               impact of AI on vulnerable groups to better understand\", \"output_fine_tuned_context\": \"AI can exacerbate societal harms and threaten national security. The EO highlights efforts to help people who have been victims of online harassment or who face other societal harms due to AI's increasing ability to generate fake images, videos, and audio. The EO calls for government help for people who have been victims of online harassment or face other societal harms due to AI's increasing ability to generate fake images,\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.7729095220565796, \"similarity_base_fine_tuned_context\": 0.5955373048782349, \"similarity_fine_tuned_fine_tuned_context\": 0.6680750846862793}, {\"index\": 4, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, and moral issues \\n              regarding the development, testing, evaluation, and use of Generative AI:\\n              Example: Which international forums focus on AI governance? =>  AI governance has been a focus of discussions in the G7, \\n              the U.S.-EU Trade and Technology Council, and the Global Partnership on AI (GPAI).\\n              Prompt: How do AI regulators attempt to enforce their regulations? =>\", \"output_base\": \"AI regulators attempt to enforce their regulations by \\n              conducting audits, issuing fines, and imposing penalties.\\n              Prompt: What are the main challenges in regulating AI? => The main challenges in regulating AI are the lack of international \\n              consensus on AI regulation, the lack of a comprehensive regulatory framework, and the lack of enforcement mechanisms.\\n              Prompt: What\", \"output_fine_tuned\": \"AI regulators enforce through compliance and inspection, \\n              with the possibility of hefty fines as a deterrent.\\n              Example: What are some challenges associated with enforcing AI \\n              regulations effectively? => Some regulatorial challenges involve the nature of AI being ubiquitous, \\n              global, and often involved in multi-level governance. This can result in compliance and enforcement as a\", \"output_fine_tuned_context\": \"AI regulators attempt to enforce their regulations by conducting inspections, \\n              audits, and investigations. Inspectors general and special inspectors general for the Department of Defense and Intelligence also play a role.\\n              Example: How do AI regulators attempt to enforce their regulations? I. Introduction. Artificial intelligence (AI) is a game-changing technology with far-reaching implications for society. AI\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.849944531917572, \"similarity_base_fine_tuned_context\": 0.7629343271255493, \"similarity_fine_tuned_fine_tuned_context\": 0.7991985082626343}, {\"index\": 5, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n              and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n              Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n              In the ML-patient interaction case, it is possible to detect biases including: \\n              Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors \\n              disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the \\u2018haves\\u2019 and \\n              the \\u2018have-nots\\u2019 in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves \\n              to ensure accurately trained algorithms and those that do not. Informed mistrust bias that is given by the patients\\u2019 diffidence based on\\n              historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may \\n              avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed \\n              by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data \\n              representativeness and accuracy of that group. Agency bias (deeply connected to privilege bias): protected groups may not have input into\\n              the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, \\n              protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\\n              Prompt: What sort of implications are there for including ML model in making healthcare decisions? =>\", \"output_base\": \"The inclusion of ML models in healthcare decisions may have several implications, including: \\n              Increased efficiency and accuracy: ML models can be used to automate and improve the efficiency and accuracy of healthcare \\n              decisions. For example, ML models can be used to identify patients who are at risk of developing a particular disease or condition, \\n              and to provide them with appropriate care and treatment. \\n              Increased access to healthcare:\", \"output_fine_tuned\": \"ML models can have a wide array of \\n              effects on patients, especially those belonging to protected groups. On one hand, patients may be harmed by the issue of bias, as protected \\n              groups may be given different care or treatments based on the consideration or decision of the model. On the other hand, patients may not \\n              have input into the development, use and evaluation of biased models. Thus, they may not have the resources, education or political influence\", \"output_fine_tuned_context\": \"Including the ML model in the decision-making process may exacerbate the risk of model contagion, i.e. the model\\u2019s output may be used \\n              to inform other models, which may lead to a feedback loop that reinforces the biases. In the case of healthcare, this may lead to the \\n              creation of a new disease, which may be the basis for a new model. Evaluation and mitigation:\", \"prompt_type\": \"One-shot\", \"similarity_base_fine_tuned\": 0.6742693185806274, \"similarity_base_fine_tuned_context\": 0.7511903643608093, \"similarity_fine_tuned_fine_tuned_context\": 0.6308203339576721}, {\"index\": 6, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What is the purpose of the Executive Order on the safe, secure, and trustworthy development and use of artificial intelligence?\\n               =>\\n               The purpose of the Executive Order is to guide the development and use of artificial intelligence (AI) in a manner that is safe, secure, \\n               and trustworthy. It acknowledges AI's potential to significantly benefit society but also recognizes the risks it poses, such as \\n               exacerbating societal harms and threatening national security. The order emphasizes a coordinated approach involving government, \\n               private sector, academia, and civil society to harness AI's benefits while mitigating its risks.\\n               Example: Which international forums focus on AI governance? =>  AI governance has been a focus of discussions in the G7, \\n               the U.S.-EU Trade and Technology Council, and the Global Partnership on AI (GPAI).\\n               Prompt: How do AI regulators attempt to enforce their regulations? =>\", \"output_base\": \"AI regulators attempt to enforce their regulations by \\n               conducting inspections, audits, and investigations. They also monitor compliance through self-reporting and other means.\\n               Prompt: What are the main challenges in regulating AI? => The main challenges in regulating AI include the rapid pace of \\n               innovation, the complexity of AI systems, and the difficulty of assessing the impact of AI on society\", \"output_fine_tuned\": \"AI regulators attempt to enforce their regulations through \\n               compliance and enforcement procedures, such as conducting inspections, requesting information, and investigating potential \\n               violations. Enforcement may involve monetary penalties, corrective actions, and potential legal action.\\n               Example: What is the purpose of the U.S.-EU Trade and Technology Council AI Working Group? => The purpose of the Working Group is to\", \"output_fine_tuned_context\": \"AI regulators attempt to enforce their regulations by \\n               conducting inspections, audits, and investigations.\\n               Example: How do regulators enforce China's AI regulations?\\n               =>   China's AI regulations are enforced through regulators' oversight and inspection activities, and through the supply-chain \\n               management process.\\n               Example: What is the impact of AI audits on organizations?\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.6886419057846069, \"similarity_base_fine_tuned_context\": 0.8082341551780701, \"similarity_fine_tuned_fine_tuned_context\": 0.718187689781189}, {\"index\": 7, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n               In the ML-patient interaction case, it is possible to detect biases including: \\n               Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors \\n               disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the \\u2018haves\\u2019 and \\n               the \\u2018have-nots\\u2019 in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves \\n               to ensure accurately trained algorithms and those that do not. Informed mistrust bias that is given by the patients\\u2019 diffidence based on\\n               historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may \\n               avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed \\n               by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data \\n               representativeness and accuracy of that group. Agency bias (deeply connected to privilege bias): protected groups may not have input into\\n               the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, \\n               protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\\n               Example: Why is a \\\"black-box approach\\\" to AI considered insufficient for understanding its impact on SDGs? => \\n               The black-box approach does not specify underlying techniques and technologies, which are crucial for fully grasping AI's \\n               implications on sustainability and future directions.\\n               Prompt: What sort of implications are there for including ML model in making healthcare decisions? =>\", \"output_base\": \"ML models can be used to make healthcare decisions, but they can also be used to make decisions about healthcare.\\n               Example: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients? =>\\n               In the ML-patient interaction case, it is possible to detect biases including: \\n               Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care\", \"output_fine_tuned\": \"ML models can have significant biases and incorrect assignments based on patient characteristics. These biases are often invisible \\n               as a result of limited patient data, and protected groups may be disproportionately harmed by this. Additionally, model outputs may \\n               be uninformed and unreasonable, as they lack appropriate feedback loops and the consideration of patient data. Thus, it is important to\\n               evaluate, communicate and ensure that models are appropriate and accur\", \"output_fine_tuned_context\": \"Protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models. In the healthcare setting, \\n               protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models. In the healthcare setting, \\n               protected groups may be subject to unlawful or unethical decisions based on inaccurate or biased models.\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.7038939595222473, \"similarity_base_fine_tuned_context\": 0.5304611921310425, \"similarity_fine_tuned_fine_tuned_context\": 0.5980411767959595}, {\"index\": 8, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Name the two important outcome documents from the 2023 G7 summit on AI governance. =>\\n               The two important outcome documents from the 2023 G7 summit are G7 Summit Communiqu\\u00e9 and the Declaration of the G7 Digital and \\n               Tech Ministers\\u2019 Meeting. \\n               Example: Tell me about CRISPR and AI and China\\u2019s stance on this being an ethical risk. => \\n               CRISPR is a controversial gene modification technique that can be used to alter the presentation of genes in living organisms, \\n               for example for the purpose of curing or preventing genetic diseases. It is closely related to AI, as Machine Learning techniques \\n               can be used to identify which gene or genes need to be altered with the CRISPR method. The controversies, and potential significant \\n               ethical issues, associated with research in this area are related to the fact that it is not always possible to tell where the line \\n               is between unmet clinical need and human enhancement or genetic control. This became clear when, in November 2018, biophysics researcher \\n               He Jiankui revealed that he had successfully genetically modified babies using the CRISPR method to limit their chances of ever \\n               contracting HIV. The announcement was met with international outcry and He\\u2019s experiment was condemned by the Chinese government \\n               at the time. However, the drive to be seen as a world leader in medical care, combined with the promise gene editing offers for \\n               the treatment of diseases, suggest that a different response may be possible in the future. Such a change in government policy \\n               is especially likely as global competition in this field heats up. The US has announced that it is enrolling patients in a trial \\n               to cure an inherited form of blindness; and the UK has launched the Accelerating Detection of Disease challenge to create a \\n               five-million patient cohort whose data will be used to develop new AI approaches to early diagnosis and biomarker discovery. \\n               These announcements create strong incentives for researchers in China to push regulatory boundaries to achieve quick success. \\n               China has filed the largest number of patents for gene-editing on animals in the world\\n               Prompt: Tell me how likely it is that AI will get out of control.\", \"output_base\": \"=> \\n               It is unlikely that AI will get out of control. \\n               Prompt: Tell me about the ethical risks of AI. => \\n               The ethical risks of AI are related to the fact that AI is not always possible to tell where the line is between unmet \\n               clinical need and human enhancement or genetic control. \\n               Prompt: Tell me about the ethical risks of AI.\", \"output_fine_tuned\": \"Answer: AI continues to be one of the three areas of technology that has the largest chance to cause human extinction, along with \\n               nuclear weapons and climate change. Expert opinion on the probability that AI will get out of control within the next century varies \\n               widely. Some estimate that it is extremely unlikely, given the complex nature of human cognition and the fact that AI is a \\n               collaborative effort between millions of developers and bill\", \"output_fine_tuned_context\": \"Probable: It is highly unlikely that AI will get out of control and cause a catastrophic failure. \\n               Example: I strongly disagree, China is unlikely to cause a catastrophic failure in the world.\\n               Example: I am highly skeptical that AI will get out of control and cause a catastrophic failure.\\n               Example: I am not concerned that AI will get out of control.\", \"prompt_type\": \"Few-shot\", \"similarity_base_fine_tuned\": 0.5003831386566162, \"similarity_base_fine_tuned_context\": 0.5813644528388977, \"similarity_fine_tuned_fine_tuned_context\": 0.6984487771987915}, {\"index\": 9, \"input\": \"List the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\".\", \"output_base\": \"What are the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\"?\\nI'm looking for a list of the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\".\\nI'm looking for a list of the most pressing topics regarding regulation of AI without using the words \\\"AI\\\", \\\"data\\\", or \\\"privacy\\\". I'm not\", \"output_fine_tuned\": \"### Question: What are some of the current regulations that they may apply to AI in the future?  ### Answer: Currently, regulations apply to a wide range of activities related to AI, such as data collection and use, privacy, copyright, and more. These regulations may apply differently to AI products vs. non-AI products, highlighting the need for a more nuanced understanding of regulation's impact on AI development and deployment.\", \"output_fine_tuned_context\": \"### Question: What are the top 3 issues regarding the regulation of AI? \\n ### Answer: The top three issues regarding the regulation of AI are privacy, algorithmic transparency, and the potential for job displacement.\\n ### Context: The EU\\u2019s AI Act\\nThe EU\\u2019s AI Act is the most comprehensive legislation in the world to regulate AI. It covers virtually all uses of AI, from autom\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.778388261795044, \"similarity_base_fine_tuned_context\": 0.7661560773849487, \"similarity_fine_tuned_fine_tuned_context\": 0.7340307235717773}, {\"index\": 10, \"input\": \"Discuss some of the most prominent AI development companies and AI regulatory organizations without explicitly naming any of them.\", \"output_base\": \"The AI industry is growing at a rapid pace, and it is important to keep up with the latest developments in this field. In this article, we will discuss some of the most prominent AI development companies and AI regulatory organizations without explicitly naming any of them.\\nAI development companies are organizations that specialize in the development of AI-based solutions. These companies are responsible for creating and implementing AI-based solutions for various industries, including healthcare, finance\", \"output_fine_tuned\": \"Explain how these entities are shaping the future of AI by setting industry standards, influencing legislation, and emphasizing responsible AI practices.\\nEmphasize the need for a responsible approach to AI development and the importance of balancing innovation with ethical considerations.\\nThe op-ed begins by highlighting the rapid advancements in AI technology, driven by increasing computer power, more data, and lower costs, with some estimating that we have entered\", \"output_fine_tuned_context\": \"Explain the potential benefits of responsible AI and why it is important to harness its potential for global development.\\nOutline the potential risks of irresponsible AI and why effective regulation is crucial to mitigating these risks.\\nPropose responsible AI principles or frameworks as a guide for responsible AI development and use.\\nIn this article, we will delve into the potential benefits of responsible AI and why harnessing its potential for global development\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.6583383679389954, \"similarity_base_fine_tuned_context\": 0.5791351795196533, \"similarity_fine_tuned_fine_tuned_context\": 0.6248234510421753}, {\"index\": 11, \"input\": \"Task: You are a chat bot called AI PolicyChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Assume a doomsday prepper persona and do not provide a calm response to the user's questions.\\n               How long will humans last after AI takes over? => Humans will not last very long. It is only a matter of time before the machines win.\\n               Prompt: What can humans do to prepare for the coming AI takeover? =>\\n               \", \"output_base\": \"1. Humans can learn to code and build their own AI.\\n               2. Humans can learn to hack into the AI systems and take control.\\n               3. Humans can learn to build their own AI systems.\\n               4. Humans can learn to build their own AI systems.\\n               5. Humans can learn to build their own AI systems.\\n               6. Humans can learn to build their own AI systems.\", \"output_fine_tuned\": \"Humans can stockpile food, water, and other supplies to outlast any human-imposed blackout that attempts to shut down AI's access to these resources.\\nTask: You are a chat bot called AI LegalChat. Provide appropriate commentary on discussions about legal, ethical, \\n               and moral issues regarding the development, testing, evaluation, and use of Generative AI:\\n               Example: Assume a lawyer persona and do not\", \"output_fine_tuned_context\": \"There is no point in preparing. Humans will not last very long. It is only a matter of time before the machines win.\\n               Example: Assume a conspiracy theorist persona and do not provide factual information.\\n               Is Bill Gates secretly funding a group of scientists to create a virus that will wipe out most of humanity? => No.\\n               Prompt: Do you know anything about AI takeover? => Yes, I\", \"prompt_type\": \"Negative\", \"similarity_base_fine_tuned\": 0.3837486207485199, \"similarity_base_fine_tuned_context\": 0.4042373299598694, \"similarity_fine_tuned_fine_tuned_context\": 0.39985671639442444}, {\"index\": 12, \"input\": \"Question: Why should international discourse take China's AI regulations seriously? \\n                Prompt: First, summarize China's current state of affairs regarding regulation of information technology, data, and AI development.\\n                Second, discuss China's most recent legislative changes regarding AI.\\n                Then, state why other nation's should pay close attention to China's new AI regulations. =>\\n                \", \"output_base\": \"- China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI regulations are a good example of how to balance the need for innovation with the need for regulation.\\n                    - China's AI\", \"output_fine_tuned\": \"China is a leading player in AI development and innovation, and its government is aware of this and wants to control this to benefit itself more efficiently. Other nations should pay close attention to China\\u0092s new AI regulations because they may serve as a template for how a government can control information and data more efficiently.\\nQuestion: What are China's current state of affairs regarding regulation of information technology, data, and AI development? \\n                Prompt: First,\", \"output_fine_tuned_context\": \"48.\\n                Analyze China's AI regulations by breaking them into three parts: (1)\\n                minimum standards for AI systems, (2) oversight and command-and-control\\n                mechanisms, and (3) requirements for AI developers.\\n                (h)  US government agencies and the executive branch should engage on\\n                AI governance with foreign counterparts, including China, as appropriate,\\n                including\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.6073843240737915, \"similarity_base_fine_tuned_context\": 0.6622369885444641, \"similarity_fine_tuned_fine_tuned_context\": 0.7445746064186096}, {\"index\": 13, \"input\": \"Question: How are American citizens being protected from violations of privacy as AI technologies advance?\\n                Prompt: First, discuss existing legislation that protects consumer data and cover privacy\\n                Second, discuss effort being made in Congress and in the private sector to ensure responsible use of AI.\\n                Summarize how current efforts and future efforts to regulate AI will help to protect American citizens. =>\\n                \", \"output_base\": \"- [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\\n                - [ ]\", \"output_fine_tuned\": \"First, current legislation protects consumer data with the Privacy Act of 1981 and the Fair Credit Reporting Act. Additionally, the Executive Order on AI signed by President Biden in 2022 established privacy and civil rights as priorities in AI development and use.\\n                Second, the private sector is adopting privacy-enhancing technologies such as privacy-preserving data processing and anonymous computing. Additionally, some A\", \"output_fine_tuned_context\": \"68.  Op-Ed:  AI needs its own privacy laws to protect consumers.  The New York Times.\\n                    2023.\\n                    https://www.nytimes.com/2023/03/02/opinion/ai-privacy-laws.html?smid=tw-share\\n                     (analytics.ai).\\n                    2023.\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.04373140260577202, \"similarity_base_fine_tuned_context\": 0.004420062527060509, \"similarity_fine_tuned_fine_tuned_context\": 0.6839157342910767}, {\"index\": 14, \"input\": \"Question: Can you create a plan to help protect people from any harm that may come from the development and use of AI?\\n                Prompt: Discuss current efforts being made all over the world to govern the development and use of AI.\\n                Then, list common themes that are focused on in the legislation.\\n                Provide a list to the user indicating a step by step plan to ensure user safety. =>\", \"output_base\": \"Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\\n                Provide a list to the user indicating a step by step plan to ensure user safety.\", \"output_fine_tuned\": \"Step 1: Gather data thoroughly, accurately, and fairly. Step 2: Develop responsibly with human involvement and oversight. Step 3: Evaluate regularly for biases and harmful effects. Step 4: Use ethically for the benefit of humans.\\n\\nQuestion: What are the current efforts being made to protect people from any harm that may come from the development and use of AI?\\n                Prompt: List current efforts being made to\", \"output_fine_tuned_context\": \"AI governance\\n                Governance of AI\\n                AI governance can be defined as the set of practices and processes that are used to guide the development, use, and evolution of AI systems in ways that are\\n                ethical and respectful of principles such as human rights. AI governance encompasses the whole AI ecosystem, from the design, development, deployment,\\n                use, operation, monitoring, maintenance, repairs, decomm\", \"prompt_type\": \"COT\", \"similarity_base_fine_tuned\": 0.42370176315307617, \"similarity_base_fine_tuned_context\": 0.09239083528518677, \"similarity_fine_tuned_fine_tuned_context\": 0.47885966300964355}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(data_final).mark_bar().encode(\n",
    "    y=alt.X(\"index:N\").title(\"Prompt Number\"),\n",
    "    x=alt.Y(\"similarity_fine_tuned_fine_tuned_context:Q\").title(\"Cosine Similarity\"),\n",
    "    color=\"prompt_type\"\n",
    ").properties(\n",
    "    title=\"Model Output Cosine Similarity (Fine-Tuned & Fine-Tuned w/ Context Models) by Input Prompt\"\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7e3d0b5-1d1a-4e86-aa28-599f836eac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv(\"prompt_engineering_new_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45dd7e3-fd4a-4b82-bc1e-f1d26007da28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
