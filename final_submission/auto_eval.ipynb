{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd360403-e7b3-4d6c-aba1-9726d6075217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89e49f-5e41-4901-ad90-1f2494a3990e",
   "metadata": {},
   "source": [
    "!pip install bert-score\n",
    "!pip install sacrebleu\n",
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8c327-498f-4309-a287-e24d5f0b6e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a469445bd294054b1aa6325187a0b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:836: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = \"./finetuned/policy-llama2-7b\"\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(finetuned_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7e297d-d677-4422-9250-9b51005a01b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5792d6e28c64471cb003b90c676f510b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:836: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "rag_model = \"./models_hf_with_rag/7B\"\n",
    "\n",
    "# Load the base  model and tokenizer\n",
    "model_rag = AutoModelForCausalLM.from_pretrained(rag_model)\n",
    "tokenizer_rag = AutoTokenizer.from_pretrained(rag_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928fea9-9315-42a2-a518-a3c0f8fc0a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc73aca621648b2b4d9c52ab54fa462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = \"./models_hf/7B\"\n",
    "\n",
    "# Load the base  model and tokenizer\n",
    "model_base = AutoModelForCausalLM.from_pretrained(base_model)\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4506979f-6025-44fb-bbea-b85fb935a3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text based on a given prompt\n",
    "def generate_text(prompt, model, tokenizer, max_length=100):\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "    # Generate text based on the prompt\n",
    "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, temperature=0.7)\n",
    "\n",
    "    # Decode the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "# prompt = \"What is the regulation around training powerful AI models in Europe?\"\n",
    "# generated_text = generate_text(prompt, model, tokenizer)\n",
    "# print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82e238-448c-43b8-9bef-94b713ac3172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefa0101-1aea-4232-bc5b-006158e650ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from sacrebleu.metrics import BLEU\n",
    "from rouge import Rouge\n",
    "\n",
    "class SimilarityEvaluator:\n",
    "    def bert_score_calc(self, cands, ref1):\n",
    "        P1, R1, F1 = score(cands, ref1, lang=\"en\", verbose=True)\n",
    "        return F1\n",
    "\n",
    "    def bleu_score_calc(self, cands, ref1):\n",
    "        bleu_scorer = BLEU()\n",
    "        score1 = bleu_scorer.sentence_score(\n",
    "            hypothesis=cands[0],\n",
    "            references=ref1,\n",
    "        )\n",
    "        return score1.score/100\n",
    "\n",
    "    def rouge_score_calc(self, cands, ref1):\n",
    "        rouge_scorer = Rouge()\n",
    "        score1 = rouge_scorer.get_scores(\n",
    "            hyps=cands[0],\n",
    "            refs=ref1[0],\n",
    "        )\n",
    "        # return score1[0]['rouge-1']['f']\n",
    "        return score1[0]['rouge-l']['f']\n",
    "\n",
    "    def evaluate_similarity(self, cands, ref1):\n",
    "        bert_score = self.bert_score_calc(cands, ref1)\n",
    "        bleu_score = self.bleu_score_calc(cands, ref1)\n",
    "        rouge_score = self.rouge_score_calc(cands, ref1)\n",
    "        return (bert_score, bleu_score, rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038ae437-c2c4-4cda-8063-5016a0d99e6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Answer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERT Score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBLEU Score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROUGE Score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Print or process the extracted input and output\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 2)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "evaluator = SimilarityEvaluator() \n",
    "\n",
    "with open(\"merged_file_test.json\", \"r\") as f, open(\"evaluation_scores_finetune.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Input\", \"Output\", \"Generated Answer\", \"BERT Score\", \"BLEU Score\", \"ROUGE Score\"])\n",
    "    \n",
    "    datas = json.load(f)\n",
    "    for data in datas:\n",
    "        # Print or process the extracted input and output\n",
    "        print(\"Input:\", data[\"input\"])\n",
    "        print(\"Output:\", data[\"output\"])\n",
    "        \n",
    "        answer = generate_text(data[\"input\"], model, tokenizer)\n",
    "        answer = answer.replace(data[\"input\"], \"\")\n",
    "        print(\"Gen answer:\", answer)\n",
    "        eval_scores = evaluator.evaluate_similarity([data[\"output\"]], [answer])\n",
    "        print(eval_scores)\n",
    "        writer.writerow([data[\"input\"], data[\"output\"], answer, eval_scores[0].tolist(), eval_scores[1], eval_scores[2]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf4bd8-e947-4fc8-8a80-931c3b35a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "evaluator = SimilarityEvaluator() \n",
    "\n",
    "with open(\"prompt_outputs2.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    datas = json.load(f)\n",
    "    for data in datas:\n",
    "        answer = generate_text(data[\"input\"], model_base, tokenizer_base)\n",
    "        answer = answer.replace(data[\"input\"], \"\")\n",
    "        eval_scores = evaluator.evaluate_similarity([data[\"output\"]], [answer])\n",
    "        print(eval_scores)\n",
    "        \n",
    "        # Open the CSV file in append mode\n",
    "        open(\"evaluation_scores_base.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            \n",
    "            # Write to the CSV fiNle\n",
    "            writer.writerow([data[\"input\"], data[\"output\"], answer, eval_scores[0].tolist(), eval_scores[1], eval_scores[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0470c-8c1e-4d0b-b68a-e0ff0176a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/achoudh2/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is the trajectory of Chinese AI governance, and what milestone is it approaching?\n",
      "Output: Chinese AI governance is heading towards drafting a comprehensive national AI law, mirroring the evolution of internet governance regulations, with a potential draft release by late 2023 or 2024 and subsequent revisions involving key stakeholders.\n",
      "Gen answer: The Chinese government has been actively promoting the development of AI, and has also been actively promoting the development of AI governance.\n",
      "In 2017, the Chinese government issued the “National New Generation Artificial Intelligence Development Plan (2017-2020)”, which proposed to promote the development of AI governance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d1f895839a42d2aa60db79983f5ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17ed42fdb9a478eb8fd0c6a874c3ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.98 seconds, 1.02 sentences/sec\n",
      "(tensor([0.8577]), 0.018975667919391207, 0.12903225306971924)\n",
      "Input: How does the Europe Artificial Intelligence Act regulate general-purpose AI systems and high-impact GPAI models?\n",
      "Output: General-purpose AI systems must be transparent, while high-impact models with systemic risks face stricter evaluation, risk mitigation, incident reporting, and cybersecurity measures.\n",
      "Gen answer: The European Commission has published the final version of the Artificial Intelligence Act (AIA), which will regulate the use of AI in the EU. The AIA will apply to all AI systems that are used in the EU, regardless of where they are developed or used.\n",
      "The AIA will regulate the use of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e718a2611c1d44dca53da737468e9c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ac22f859c846a6a6c9973bb1fd5c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 13.79 sentences/sec\n",
      "(tensor([0.8421]), 0.010669118228812675, 0.07142856665816359)\n",
      "Input: How do providers of high-risk AI systems manage post-market monitoring according to Europe Commission?\n",
      "Output: Providers follow a step-by-step process, including conformity assessment and registration. Post-market, authorities conduct surveillance, users ensure human oversight, and providers implement monitoring systems, reporting incidents and malfunctions.\n",
      "Gen answer: The European Commission has published a new document on the post-market monitoring of high-risk AI systems. The document is a response to the European Parliament’s request for an opinion on the post-market monitoring of high-risk AI systems.\n",
      "The document is a response to the European Parliament’s request for an opinion on the post-market monitoring of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e624e62a1840a8b7089fc5575c8c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8798780a0c448d9930185d717a5f8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.57 sentences/sec\n",
      "(tensor([0.8370]), 0.0082753035194127, 0.08163264806330726)\n",
      "Input: What are the cross-sectoral principles of the UK regulatory framework, and how will they be implemented?\n",
      "Output: The principles cover safety, transparency, fairness, accountability, and contestability. Regulators will implement them through guidance, technical standards, and assurance techniques.\n",
      "Gen answer: The cross-sectoral principles are:\n",
      "The UK regulatory framework will be based on the principles of proportionality, accountability, transparency, and consistency.\n",
      "The UK regulatory framework will be based on the principles of proportionality, accountability, transparency, and consistency. The UK regulatory framework will be based on the principles of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfb93a12fc74be1bfeb261294f88231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4497c6a1f2664b7997cd19415511f96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.08 seconds, 12.08 sentences/sec\n",
      "(tensor([0.8728]), 0.04279641176459531, 0.2702702652739226)\n",
      "Input: What are some of the jobs that may be affected by Generative AI in the UK?\n",
      "Output: Generative AI has the possibility to affect many chosen careers across the UK. These affects can range from providing assistive technology to posing an existential threat to some forms of work. Careers that are highly technical and require a large amount of human responsibility such as medical careers are largely safe, as are careers that require a diverse amount of manual labor. However, low skill jobs that are largely repetitive are at risk of becoming obsolete and others may be at risk of being subject to AI driven management automation.\n",
      "Gen answer: The UK is home to a diverse range of industries, and as the use of generative AI continues to grow, it is likely that some jobs will be affected. Here are some of the jobs that may be affected by generative AI in the UK:\n",
      "Content Creators: Generative AI can be used to create content such as articles, blog posts, and social media\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161202bf280d4e49ab0dbf968679b27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a86ff4b4b624a45a8c3bb7a8eb9705c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.08 seconds, 12.69 sentences/sec\n",
      "(tensor([0.8613]), 0.023238298670798466, 0.2909090860743802)\n",
      "Input: In what ways will the Federal Government lead global efforts in the responsible development and use of AI?\n",
      "Output: The administration seeks to lead by developing frameworks for AI risk management and safety with international allies, promoting responsible AI principles globally, and engaging in collaborations to ensure AI benefits are shared worldwide without exacerbating inequities or harming human rights.\n",
      "Gen answer: The Federal Government will lead global efforts in the responsible development and use of AI by:\n",
      "Establishing a National AI Strategy that will set out a vision for the responsible development and use of AI in Australia, including a commitment to the responsible development and use of AI in Australia’s international engagement.\n",
      "Establishing a National AI Centre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46152365ef4145e1ab2be8aee483d2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bd545157504b83b4811b4096f6b78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.54 sentences/sec\n",
      "(tensor([0.8724]), 0.011295087622315632, 0.2028985457340896)\n",
      "Input: What rights do individuals have to notice and explanation regarding the use of automated systems?\n",
      "Output: Individuals have the right to clear and accessible information about the use of automated systems, including how and why they impact outcomes. Systems should provide explanations that are meaningful and useful, with public reporting on the clarity and quality of this information.\n",
      "Gen answer: The right to notice and explanation is a fundamental right of individuals. It is a right that is recognized in the European Union and in many other countries. The right to notice and explanation is a right that is recognized in the European Union and in many other countries.\n",
      "The right to notice and explanation is a fundamental right of individuals. It is a right that is recognized in the European Union and in many other\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d85896864471abe7d1a5c9b77b454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a0947d3b5148e48083e707b13cb684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 13.60 sentences/sec\n",
      "(tensor([0.8345]), 0.012346287149618109, 0.21428570959821439)\n",
      "Input: How does this initiative fit into the broader efforts of the Biden-Harris Administration regarding AI?\n",
      "Output: This initiative is part of a whole-of-government effort to address AI technology, with the Biden-Harris Administration announcing commitments from companies to advance safe and trustworthy AI and seeking bipartisan legislation for responsible AI development.\n",
      "Gen answer: The Biden-Harris Administration is committed to ensuring that AI is developed and deployed in a way that benefits all Americans. The Administration is committed to ensuring that AI is developed and deployed in a way that benefits all Americans. The Administration is committed to ensuring that AI is developed and deployed in a way that benefits all Americans. The Administration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae75e56c9d95457abbeb02a906cce563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca6ded2a47e4070b4844c2d895d9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.45 sentences/sec\n",
      "(tensor([0.8720]), 0.015160415454697328, 0.24999999531250006)\n",
      "Input: What role does EPIC play in AI policy development, and what stance does it take on these issues?\n",
      "Output: EPIC advocates for comprehensive privacy protections, rigorous testing protocols, expanded resources for evaluating AI systems, and a government-wide effort to combat algorithmic discrimination. It tracks AI legislation at state and local levels and emphasizes the need for policies that protect individuals from algorithmic harm.\n",
      "Gen answer: EPIC is a non-profit public interest research center that focuses on the intersection of technology and civil liberties. We are a think tank, but we also do advocacy and litigation. We have a very strong focus on AI and the impact of AI on civil liberties.\n",
      "We have a number of projects that are focused on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cef41b3ce6466fbbfbd65276451a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e53c6583844f82958abbb74b059585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.10 sentences/sec\n",
      "(tensor([0.8578]), 0.011070886201655241, 0.15999999500088904)\n",
      "Input: How might the government ensure that people negatively affected by AI can receive help?\n",
      "Output: The government could help people negatively affecteed by AI in several ways that are currently available. There are numerous agencies that can support individuals who are victim to discrimination based on race, religion, sex, gender, etc. Additionally, providing a way for whistleblowers to voice their concerns anonymously could help government agencies to address issues with AI more quickly.\n",
      "Gen answer: The government should ensure that people negatively affected by AI can receive help by providing financial assistance, job training, and mental health support.\n",
      "The government should provide financial assistance to those who have been negatively affected by AI. This could include unemployment benefits, job training, and other forms of assistance.\n",
      "The government should also provide job training to those who have been negatively affected by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf648a794d74949b17412afd3c92448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd51cd72bc74f8f9392a4e455049833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 13.86 sentences/sec\n",
      "(tensor([0.8644]), 0.02452363574989961, 0.275862064019025)\n",
      "Input: Why is it difficult to regulate AI? \n",
      "Output: AI is a general-purpose technology that is likely to be ubiquitous and apply to a wide range of applications. This makes it harder to regulate well.\n",
      "Gen answer: 10 reasons\n",
      "10 reasons.\n",
      "The development of artificial intelligence (AI) is progressing rapidly. In the past few years, AI has been used in many areas, such as autonomous driving, medical diagnosis, and financial services. However, the development of AI also raises many ethical and legal issues.\n",
      "In this article, we will discuss the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea7ca1707c54e848dbe3beb51099dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ad3d610ccf40c98999aec1014fc2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.00 sentences/sec\n",
      "(tensor([0.8476]), 0.005575000289382507, 0.092307687829586)\n",
      "Input: Why was the U.S concerned about Chinas breakthrough in AI research? \n",
      "Output: U.S. political and military leaders were concerned that China's newfound AI capabilities would provide it with an asymmetric military advantage over the United States.\n",
      "Gen answer:  Chinas AI research is a threat to the U.S.\n",
      " Chinas AI research is a threat to the U.S.\n",
      "The U.S. is concerned about Chinas breakthrough in AI research because Chinas AI research is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc55a38c00f14ccd83d96adbce9c20b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5ed8cbc00440908cba96d0a8c206d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.55 sentences/sec\n",
      "(tensor([0.8641]), 0.056141400967573224, 0.2439024341701369)\n",
      "Input: Why is U.S. leadership on AI governance crucial? \n",
      "Output: U.S. leadership on AI governance is critical, particularly given the role of the U.S. as a leading developer and investor in AI, including more recently foundational AI models such as ChatGPT4.\n",
      "Gen answer: 1. The U.S. is a global leader in AI research and development. 2. The U.S. has a strong track record of promoting international cooperation on AI. 3. The U.S. has a unique opportunity to shape the global AI governance landscape. 4. The U.S. can play a key role in ensuring that AI is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aa263c5243400e9c04fdbd7b47a722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e12e02d402420594995502000e06fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.46 sentences/sec\n",
      "(tensor([0.8872]), 0.072807292727477, 0.24242423753902673)\n",
      "Input: Which international organizations are likely to spearhead the development of tools for trustworthy AI? \n",
      "Output: The first expected drivers of such tools are international organizations such as the OECD and United Nations Educational, Scientific and Cultural Organization (UNESCO), as well as multi-stakeholder initiatives such as the GPAI.\n",
      "Gen answer: 1. Which international organizations are likely to spearhead the development of tools for trustworthy AI?\n",
      "1. Which international organizations are likely to spearhead the development of tools for trustworthy AI?\n",
      "2. What are the main challenges to the development of tools for trustworthy AI?\n",
      "3. What are the main challenges to the development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73975704901443188fd9df7f28975c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a8b76f0fbf4d4ba7ad22277a4f21a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.58 sentences/sec\n",
      "(tensor([0.8290]), 0.015136322184533623, 0.17777777283950633)\n",
      "Input: How effective are current US export controls at limiting the unlawful sale and distribution of advanced technologies?\n",
      "Output: Currently, export controls are not very effective at restricting access to advanced technology, foreign agents devote large amounts of resources to circumvent existing US export controls. Evidence has been found indicating the presence of Western manufacured technology like microchips in sanctioned nations' missiles.\n",
      "Gen answer: The US government has a long history of export controls, which are intended to limit the unlawful sale and distribution of advanced technologies. However, the effectiveness of these controls has been called into question in recent years, as the proliferation of advanced technologies has increased.\n",
      "One of the main concerns is that export controls are not always effective in preventing the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b47e72494e54514aea201c530997f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d95141cd414d09afa89f11b74d5825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.15 sentences/sec\n",
      "(tensor([0.8761]), 0.05518377732218169, 0.285714280739796)\n",
      "Input: How does AI potentially impact the Sustainable Development Goals (SDGs)?\n",
      "Output: AI could enable the accomplishment of 134 SDG targets but also inhibit 59 targets, highlighting its dual potential to both advance and challenge global sustainability efforts.\n",
      "Gen answer: The Sustainable Development Goals (SDGs) are a set of 17 global goals that aim to achieve a better and more sustainable future for all. The SDGs were adopted by the United Nations in 2015 and are a call to action for all countries to work together to achieve these goals by 2030.\n",
      "The SD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af65785d6eb24317873749d3d9d38436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70bbdad02844dfe85a7eca846bbb966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.64 sentences/sec\n",
      "(tensor([0.8530]), 0.007158442069608654, 0.12121211643709846)\n",
      "Input: What challenges are identified in achieving effective AI governance?\n",
      "Output: The opacity of AI systems due to their complexity or commercial secrecy, territorial and fragmented governance, and the global reach of AI necessitating a coordinated international response to manage its development, deployment, and use effectively are some of the challenges identified in achieving effective AI governance.\n",
      "Gen answer: What are the key challenges in achieving effective AI governance?\n",
      "What are the challenges in achieving effective AI governance?\n",
      "What are the challenges in achieving effective AI governance quizlet?\n",
      "What are the challenges in achieving effective AI governance quizlet?\n",
      "What are the challenges in achieving effective AI governance in the workplace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd20342ce2641d397fb20e0b0dcee1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab76ed21d224c77a643f0bf462759f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.58 sentences/sec\n",
      "(tensor([0.8561]), 0.08138023477589043, 0.31372548639753944)\n",
      "Input: What recourse is available if access to information is denied under the AI Policy?\n",
      "Output: Individuals can file an appeal if they believe access has been improperly or unreasonably denied, with a structured process for reviewing decisions, including a potential appeal to the Access to Information Committee and the AI Appeals Board.\n",
      "Gen answer: The AI Policy does not provide for any specific remedies for denial of access to information. However, the Act provides for a number of remedies for denial of access to information. These include:\n",
      "An appeal to the Information Commissioner, who may order the public body to provide the information or to pay compensation to the applicant.\n",
      "An appeal to the courts, which\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fa9ddd34324270bcfb9f6efbb0aec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79982b8db6d94cd0a26f0492a425ad9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 13.86 sentences/sec\n",
      "(tensor([0.8652]), 0.02476748083588415, 0.1971830936163461)\n",
      "Input: What role does international cooperation play in the governance of AI technologies?\n",
      "Output: International cooperation is crucial for developing a common understanding of AI, sharing good practices, and creating an evidence base to inform the design, implementation, and evaluation of AI policies.\n",
      "Gen answer: The governance of AI technologies is a complex and multifaceted issue that requires the involvement of various stakeholders, including governments, industry, academia, and civil society. International cooperation plays a crucial role in the governance of AI technologies by providing a platform for stakeholders to share knowledge, exchange ideas, and collaborate on the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b922639470a840709254e51b9057911b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7a8a4df31a4a55ae7af5f990978077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.53 sentences/sec\n",
      "(tensor([0.8817]), 0.02739668992592811, 0.23529411285899662)\n",
      "Input: Does the World Bank regularly disclose any information pursuant to its list of exceptions?\n",
      "Output: Yes, the World Bank regularly declassifies documents using a policy of 5 years for documents classified as \"Official Use Only\" and 20 years for documents classified as \"Confidential\", or \"Strictly Confidential\".\n",
      "Gen answer: Yes, the World Bank regularly discloses information pursuant to its list of exceptions.\n",
      "Does the World Bank publish a list of all information it regularly discloses pursuant to its list of exceptions?\n",
      "Yes, the World Bank publishes a list of all information it regularly discloses pursuant to its list of exceptions.\n",
      "Does the World Bank publish a list of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b9f94ff86d47999633ca68387dbb7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5849cf0eb5db4e68bb0b2880f21b794f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 13.97 sentences/sec\n",
      "(tensor([0.8394]), 0.0705803233549294, 0.31111110617283955)\n",
      "Input: What are the possible biases that have been detected in healthcare ML produced by ML interactions with patients?\n",
      "Output: In the ML-patient interaction case, it is possible to detect biases including: \n",
      "Privilege bias, i.e. some models may be unavailable in settings where protected groups receive care or require technology/sensors disproportionately available to the nonprotected class, and this also exacerbates existing inequalities between the haves and the have-nots in terms of access to the digital healthcare ecosystem; in other words, those that generate enough data on themselves to ensure accurately trained algorithms and those that do not.\n",
      "Informed mistrust bias that is given by the patients diffidence based on historical exploitation and unethical practices; protected groups may believe that a model is biased against them, and these patients may avoid seeking care from clinicians or systems that use the model or deliberately omit information, while the protected group may be harmed by this, as it results in them not receiving appropriate care and not interacting with the model, as it enhances the issue of lack of data representativeness and accuracy of that group.\n",
      "Agency bias (deeply connected to privilege bias): protected groups may not have input into the development, use and evaluation of models. Thus, they may not have the resources, education or political influence to detect biases, protest and force correction concerning the consideration or treatment of patients, especially those belonging to protected groups.\n",
      "Gen answer: What are the possible biases that have been detected in health\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64da57ed63c4fae996c0426ab949e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c851a2a907437294e4cd655d2cf28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.09 seconds, 10.68 sentences/sec\n",
      "(tensor([0.8216]), 0.0022912914690101506, 0.08108107970507673)\n",
      "Input: How might AI affect competition between nations in the future?\n",
      "Output: If development and competition within the field of Artificial Intelligence largely continues unchecked, it could precipitate a different form of arms race with a wide range of detrimental economic factors as powerful nations attempt to control compute resources and materials necessary to build more complex AI models.\n",
      "Gen answer: The future of AI is a topic that has been discussed by many experts in the field. Some believe that AI will lead to a new era of competition between nations, while others believe that it will lead to a more cooperative world.\n",
      "There are a number of ways in which AI could affect competition between nations. One possibility is that AI could be used to develop new weapons systems that are more powerful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df28f999f2a48758d8c1ee6b40c1158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8110fdb48342c089636f8e08d19361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.63 sentences/sec\n",
      "(tensor([0.8691]), 0.014270557825904431, 0.21978021480980567)\n",
      "Input: How will Singapore contribute to international AI developments? \n",
      "\n",
      "Output: (1) Anchoring key bilateral relationships with selected partners from government and industry, through substantive initiatives and technical cooperation. These will allow Singapore to “start small and move quickly”, to establish common ground with like-minded partners, as pathfinders to broad-based multilateral cooperation. \n",
      "(2) Demonstrating alignment with key international fora and supporting worthwhile platforms. Singapore will support and actively participate in substantive multilateral, multi-stakeholder, or plurilateral initiatives, that seek to achieve an inclusive, practical, and rules-based global environment for AI. \n",
      "(3) Sharing Singapore’s experience and curating meaningful partnerships for capacity building. We will actively profile Singapore’s approaches to AI through public engagements and conferences such as Asia Tech x Singapore and SCAI. We are the convenor of the Forum of Small States (FOSS), which now has a digital pillar of engagement. Together with government and industry partners, we will develop AI-related capacity building initiatives to benefit the 108 members of FOSS.\n",
      "\n",
      "Gen answer: Singapore is a small country with a big ambition. It is a global leader in many areas, including finance, technology, and education.\n",
      "Singapore is also a leader in artificial intelligence (AI). The country has a strong AI ecosystem, with a number of companies and research institutions working on AI projects.\n",
      "Singapore is also a member of the Global Partnership on A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383dc7d4c3fb403ca1d6b02e7c15c844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a69fe59409408699f2076e24598c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.08 seconds, 12.56 sentences/sec\n",
      "(tensor([0.8379]), 0.011048236961414284, 0.1342281839304537)\n",
      "Input: What are the basic principles of China’s New Generation Artificial Intelligence Development\n",
      "Output: (1) Technology-Led. Grasp the global development trend of AI, highlight the deployment of forward-looking research and development, explore the layout in key frontier domains, long-term support, and strive to achieve transformational and disruptive breakthroughs in theory, methods, tools, and systems; comprehensively enhance original innovation capability in AI, accelerate the construction of a first-mover advantage, to achieve high-end leading development.\n",
      "(2) Systems Layout. According to the different characteristics of foundational research, technological research and development, industrial development, and commercial applications, formulate a targeted systems development strategy. Fully give play to the advantages of the socialist system to concentrate forces to do major undertakings, promote the planning and layout of projects, bases, and a talent pool, organically link already-deployed major projects and new missions, continue current urgent needs and long-term development echelons, construct innovation capacity, create a collaborative force for institutional reforms and the policy environment.\n",
      "(3) Market-Dominant. Follow the rules of the market, remain oriented toward application, highlight companies’ choices on the technological line and primary role in the development of commercial product standards, accelerate the commercialization of AI technology and results, and create a competitive advantage. Grasp well the division of labor between government and the market, better take advantage of the government in planning and guidance, policy support, security and guarding, market regulation, environmental construction, the formulation of ethical regulations, etc.\n",
      "(4) Open-Source and Open. Advocate the concept of open-source sharing, and promote the concept of industry, academia, research, and production units each innovating and in principal pursuing joint innovation and sharing. Follow the coordinated development law for economic and national defense construction; promote two-way conversion and application for military and civilian scientific and technological achievements and co-construction and sharing of military and civilian innovation resources; form an all-element, multi-domain, highly efficient new pattern of civil-military integration. Actively participate in global research and development and management of AI, and optimize the allocation of innovative resources on a global scale.\n",
      "\n",
      "Gen answer: Plan?\n",
      "China’s New Generation Artificial Intelligence Development Plan was released in July 2017. It is a national plan to develop AI in China. The plan is divided into three parts:\n",
      "1. Basic principles of the plan\n",
      "2. Development goals and strategies\n",
      "3. Implementation measures\n",
      "The basic principles of the plan are as follows:\n",
      "1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b7f59013bc4d37942215b70e922376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafd4f24525c4af8a596843ee022ab29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.11 seconds, 8.80 sentences/sec\n",
      "(tensor([0.8094]), 0.003940330093802403, 0.05150214291292913)\n",
      "Input: The UK Department for Science, Innovation, and Technology (DSIT) released on March 29, 2023 an artificial intelligence (AI) white paper to describe its new approach to regulating AI. Describe the white paper in general.\n",
      "Output: The proposal seeks to create a pro-innovation regulatory framework that promotes public trust in AI by creating rules proportionate to the risks associated with different sectors’ use of AI. It also commits to establishing a regulatory sandbox to bring together regulators and innovators, so they better understand how regulation affects emerging AI technologies.\n",
      "Gen answer: The white paper is a 10-page document that describes the UK government’s approach to regulating AI. It outlines the government’s commitment to ensuring that AI is developed and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81969cafdb9647c2b19b6fe6d65d2ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5043e16b30f842098eaf59cd34fc6d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.90 sentences/sec\n",
      "(tensor([0.8778]), 0.033422819597018004, 0.20588234856401397)\n",
      "Input: At the heart of the EU AI act stands its risk categorization system, what belong to the unacceptable risk systems?\n",
      "Output: Risk systems include those that have a significant potential for manipulation either through subconscious messaging and stimuli, or by exploiting vulnerabilities like socioeconomic status, disability, or age. AI systems for social scoring, a term that describes the evaluation and treatment of people based on their social behavior, are also banned. \n",
      "Gen answer: The EU AI Act defines the following as unacceptable risk systems:\n",
      "Systems that are likely to cause physical or psychological harm to humans or damage to property.\n",
      "Systems that are likely to cause serious damage to the environment.\n",
      "Systems that are likely to cause serious damage to the health of humans or animals.\n",
      "Systems that are\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db11422feef64e419ac54efeff77dfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1eb4fc58ca443ebb48c91aa8cff79c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 13.91 sentences/sec\n",
      "(tensor([0.8417]), 0.011008819230561804, 0.1643835568549448)\n",
      "Input: What was the purpose of developing a set of overarching questions for each dimension of posture assessment in the AI assessment for the Department of Defense?\n",
      "Output: The set of overarching questions for each dimension of posture assessment served as broad themes in the interview protocols to guide data collection efforts and later formed the basis of the code tree used to analyze the interview notes\n",
      "Gen answer: The purpose of developing a set of overarching questions for each dimension of posture assessment in the AI assessment for the Department of Def\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e62439576b40f9b6c0762e973de986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee272662956049cd8ef27b02ccdcb577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to enable `effective_order` for sentence-level BLEU.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.07 seconds, 14.82 sentences/sec\n",
      "(tensor([0.8850]), 0.25540636397110394, 0.47999999539200017)\n",
      "Input: What are some of the key principles outlined in the White House's Blueprint for an AI Bill of Rights? \n",
      "Output: The Blueprint emphasizes principles such as the right to safe automated systems, protection from algorithmic discrimination, data privacy, notice of AI use, and meaningful human alternatives \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "evaluator = SimilarityEvaluator() \n",
    "\n",
    "with open(\"merged_file_test.json\", \"r\") as f:\n",
    "    datas = json.load(f)\n",
    "    for data in datas:\n",
    "        # Print or process the extracted input and output\n",
    "        print(\"Input:\", data[\"input\"])\n",
    "        print(\"Output:\", data[\"output\"])\n",
    "        \n",
    "        answer = generate_text(data[\"input\"], model_rag, tokenizer_rag)\n",
    "        answer = answer.replace(data[\"input\"], \"\")\n",
    "        answer = answer.split(\"Context:\")[0].strip()\n",
    "        print(\"Gen answer:\", answer)\n",
    "        eval_scores = evaluator.evaluate_similarity([data[\"output\"]], [answer])\n",
    "        print(eval_scores)\n",
    "        \n",
    "        # Open the CSV file in append mode\n",
    "        with open(\"evaluation_scores_rag.csv\", \"a\", newline=\"\") as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            \n",
    "            # Write to the CSV fiNle\n",
    "            writer.writerow([data[\"input\"], data[\"output\"], answer, eval_scores[0].tolist(), eval_scores[1], eval_scores[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5743da6-6ccb-420c-94df-2b00d481500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = generate_text(prompt, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NGC PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
